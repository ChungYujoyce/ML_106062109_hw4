{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from math import exp\n",
    "import matplotlib.pyplot as plt\n",
    "# process data label as 0, 1, 2 for training\n",
    "def loadDataset(dataset): \n",
    "    newdata = []\n",
    "    for x in range(len(dataset)-1):\n",
    "        for i in range(0,len(dataset[x]),4):\n",
    "            if dataset[x][i] == \"I\": # encounter labels, change it\n",
    "                if dataset[x][-3:-1] == \"sa\": # Iris-setosa\n",
    "                    newdata.append(0)\n",
    "                elif dataset[x][-2:-1] == \"r\": # Iris-versicolor\n",
    "                    newdata.append(1)\n",
    "                elif dataset[x][-3:-1] == \"ca\": # Iris-virginica\n",
    "                    newdata.append(2) \n",
    "                break\n",
    "            else:\n",
    "                attribute = float(dataset[x][i:i+3])\n",
    "                newdata.append(attribute)\n",
    "        trainingSet.append(newdata)       \n",
    "        newdata = [] # clear the package\n",
    "    return trainingSet\n",
    "\n",
    "# find the range of data to do normalize\n",
    "def dataset_minmax(dataset): # zip a(1,2,3) , b(4,5,6) to [(1,4), (2,5), (3,6)] \n",
    "    minmax = list()\n",
    "    stats = [[min(column), max(column)] for column in zip(*dataset)] # unzip the file\n",
    "    return stats\n",
    "\n",
    "# rescale data to range 0~1\n",
    "def normalize_data(dataset, minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row)-1):\n",
    "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "\n",
    "# calculate neuron activation for an input\n",
    "def activate(weights, inputs):\n",
    "    activation = weights[-1]\n",
    "    for i in range(len(weights)-1):\n",
    "        activation += weights[i] * inputs[i]\n",
    "    return activation\n",
    "\n",
    "# transfer neuron activation \n",
    "def transfer(activation):\n",
    "    return 1.0 / (1.0 + exp(-activation))\n",
    "\n",
    "# calculate the derivative of an neuron output\n",
    "def transfer_derivative(output):\n",
    "    return output * (1.0 - output)\n",
    "\n",
    "#forward propagate input to a network output\n",
    "def forward_propagate(network, row):\n",
    "    inputs = row\n",
    "    for layer in network:\n",
    "        new_inputs = []\n",
    "        for neuron in layer:\n",
    "            activation = activate(neuron['weights'], inputs)\n",
    "            neuron['output'] = transfer(activation)\n",
    "            new_inputs.append(neuron['output'])\n",
    "        inputs = new_inputs # keep updating the neurons\n",
    "    return inputs\n",
    "\n",
    "# backpropagate error and sotre in neurons\n",
    "def backward_propagate_error(network, expected): \n",
    "    for i in reversed(range(len(network))):\n",
    "        layer = network[i]\n",
    "        errors = list()\n",
    "        if i != len(network)-1:\n",
    "            for j in range(len(layer)): # hidden\n",
    "                error = 0.0\n",
    "                for neuron in network[i+1]:\n",
    "                    error += (neuron['weights'][j] * neuron['delta'])\n",
    "                errors.append(error) \n",
    "        else:\n",
    "            for j in range(len(layer)): # output\n",
    "                neuron = layer[j]\n",
    "                errors.append(expected[j] - neuron['output'])\n",
    "        for j in range(len(layer)):\n",
    "            neuron = layer[j]\n",
    "            neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
    "\n",
    "# update network weights with error\n",
    "def update_weights(network, row, learning_rate):\n",
    "    for i in range(len(network)):\n",
    "        inputs = row[:-1]\n",
    "        if i != 0:\n",
    "            inputs = [neuron['output'] for neuron in network[i - 1]]\n",
    "        for neuron in network[i]:\n",
    "            for j in range(len(inputs)):\n",
    "                neuron['weights'][j] += learning_rate * neuron['delta'] * inputs[j]\n",
    "                neuron['weights'][-1] += learning_rate * neuron['delta']\n",
    "            \n",
    "def train_network(network, train, learning_rate, n_epoch, n_outputs):\n",
    "    print(\"--------------- lrate=%.3f\" % learning_rate ,\"-----------------\")\n",
    "    prev_MSE = 0\n",
    "    MSE = 0\n",
    "    abs_fraction_of_change = 0\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        MSE = 0\n",
    "        sum_error = 0\n",
    "        for row in train:\n",
    "            outputs = forward_propagate(network, row)\n",
    "            expected = [0 for i in range(n_outputs)]\n",
    "            expected[row[-1]] = 1 # one hot encoding !!!\n",
    "            backward_propagate_error(network, expected)\n",
    "            update_weights(network, row, learning_rate)\n",
    "            update_outputs = forward_propagate(network, row) # update forward results\n",
    "            sum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
    "            MSE += sum([(expected[i] - update_outputs[i])**2 for i in range(len(expected))])\n",
    "            #print(MSE)\n",
    "        MSE /= len(expected)\n",
    "        if epoch > 0:\n",
    "            abs_fraction_of_change = abs((MSE - prev_MSE) / prev_MSE )\n",
    "            if abs_fraction_of_change <= 10e-5:\n",
    "                print(\"Epoch need:%d\"%(epoch))\n",
    "                break\n",
    "        print('>epoch=%d, MSE=%.3f, abs fraction of change=%.6f' % (epoch, MSE, abs_fraction_of_change))\n",
    "        #print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, learning_rate, sum_error))\n",
    "        prev_MSE = MSE\n",
    "        #print(\"prev\",prev_MSE)\n",
    "    return (epoch+1)\n",
    "   \n",
    "\n",
    "def init_network(n_inputs, n_hidden, n_outputs): \n",
    "# create n_hidden neurons and each neuron in the hidden layer has n_inputs + 1 weights\n",
    "    network = list() \n",
    "    hidden_layer1 = [{'weights': [(random.random()-0.5)/5.0 for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
    "    network.append(hidden_layer1) \n",
    "    hidden_layer2 = [{'weights': [(random.random()-0.5)/5.0 for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
    "    network.append(hidden_layer2)\n",
    "    output_layer = [{'weights': [(random.random()-0.5)/5.0  for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
    "    network.append(output_layer) \n",
    "    return network\n",
    "\n",
    "# make a prediction with a network\n",
    "# It returns the index in the network output that has the largest probability. \n",
    "# Assuming that class values have been converted to integers starting at 0. [0,1,2]\n",
    "def predict(network, row):\n",
    "    outputs = forward_propagate(network, row)\n",
    "    #print(outputs)\n",
    "    return outputs.index(max(outputs))\n",
    "\n",
    "# backpropagation with stochastic gradient descent\n",
    "def back_propagate(train, learning_rate, n_epoch, n_hidden):\n",
    "    n_inputs = len(train[0]) - 1\n",
    "    n_outputs = len(set([row[-1] for row in train]))\n",
    "    network = init_network(n_inputs, n_hidden, n_outputs)\n",
    "    epoch = train_network(network, train, learning_rate, n_epoch, n_outputs)\n",
    "    return epoch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet=[]\n",
    "testSet=[]\n",
    "results = []\n",
    "f = open('iris.data.txt', \"r\")\n",
    "lines = f.readlines()\n",
    "dataset = list(lines)\n",
    "trainingSet = loadDataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- lrate=0.100 -----------------\n",
      ">epoch=0, MSE=23.673, abs fraction of change=0.000000\n",
      ">epoch=1, MSE=27.338, abs fraction of change=0.154859\n",
      ">epoch=2, MSE=27.696, abs fraction of change=0.013074\n",
      ">epoch=3, MSE=27.731, abs fraction of change=0.001284\n",
      ">epoch=4, MSE=27.747, abs fraction of change=0.000570\n",
      ">epoch=5, MSE=27.762, abs fraction of change=0.000522\n",
      ">epoch=6, MSE=27.776, abs fraction of change=0.000514\n",
      ">epoch=7, MSE=27.790, abs fraction of change=0.000509\n",
      ">epoch=8, MSE=27.804, abs fraction of change=0.000504\n",
      ">epoch=9, MSE=27.818, abs fraction of change=0.000499\n",
      ">epoch=10, MSE=27.832, abs fraction of change=0.000494\n",
      ">epoch=11, MSE=27.845, abs fraction of change=0.000489\n",
      ">epoch=12, MSE=27.859, abs fraction of change=0.000484\n",
      ">epoch=13, MSE=27.872, abs fraction of change=0.000480\n",
      ">epoch=14, MSE=27.885, abs fraction of change=0.000475\n",
      ">epoch=15, MSE=27.899, abs fraction of change=0.000470\n",
      ">epoch=16, MSE=27.912, abs fraction of change=0.000465\n",
      ">epoch=17, MSE=27.924, abs fraction of change=0.000460\n",
      ">epoch=18, MSE=27.937, abs fraction of change=0.000455\n",
      ">epoch=19, MSE=27.950, abs fraction of change=0.000450\n",
      ">epoch=20, MSE=27.962, abs fraction of change=0.000445\n",
      ">epoch=21, MSE=27.974, abs fraction of change=0.000440\n",
      ">epoch=22, MSE=27.987, abs fraction of change=0.000435\n",
      ">epoch=23, MSE=27.999, abs fraction of change=0.000430\n",
      ">epoch=24, MSE=28.011, abs fraction of change=0.000425\n",
      ">epoch=25, MSE=28.022, abs fraction of change=0.000421\n",
      ">epoch=26, MSE=28.034, abs fraction of change=0.000416\n",
      ">epoch=27, MSE=28.045, abs fraction of change=0.000411\n",
      ">epoch=28, MSE=28.057, abs fraction of change=0.000406\n",
      ">epoch=29, MSE=28.068, abs fraction of change=0.000401\n",
      ">epoch=30, MSE=28.079, abs fraction of change=0.000396\n",
      ">epoch=31, MSE=28.090, abs fraction of change=0.000392\n",
      ">epoch=32, MSE=28.101, abs fraction of change=0.000387\n",
      ">epoch=33, MSE=28.112, abs fraction of change=0.000382\n",
      ">epoch=34, MSE=28.122, abs fraction of change=0.000377\n",
      ">epoch=35, MSE=28.133, abs fraction of change=0.000373\n",
      ">epoch=36, MSE=28.143, abs fraction of change=0.000368\n",
      ">epoch=37, MSE=28.153, abs fraction of change=0.000363\n",
      ">epoch=38, MSE=28.164, abs fraction of change=0.000359\n",
      ">epoch=39, MSE=28.174, abs fraction of change=0.000354\n",
      ">epoch=40, MSE=28.183, abs fraction of change=0.000349\n",
      ">epoch=41, MSE=28.193, abs fraction of change=0.000345\n",
      ">epoch=42, MSE=28.203, abs fraction of change=0.000340\n",
      ">epoch=43, MSE=28.212, abs fraction of change=0.000336\n",
      ">epoch=44, MSE=28.222, abs fraction of change=0.000332\n",
      ">epoch=45, MSE=28.231, abs fraction of change=0.000327\n",
      ">epoch=46, MSE=28.240, abs fraction of change=0.000323\n",
      ">epoch=47, MSE=28.249, abs fraction of change=0.000319\n",
      ">epoch=48, MSE=28.258, abs fraction of change=0.000314\n",
      ">epoch=49, MSE=28.267, abs fraction of change=0.000310\n",
      ">epoch=50, MSE=28.275, abs fraction of change=0.000306\n",
      ">epoch=51, MSE=28.284, abs fraction of change=0.000302\n",
      ">epoch=52, MSE=28.292, abs fraction of change=0.000298\n",
      ">epoch=53, MSE=28.300, abs fraction of change=0.000294\n",
      ">epoch=54, MSE=28.309, abs fraction of change=0.000290\n",
      ">epoch=55, MSE=28.317, abs fraction of change=0.000286\n",
      ">epoch=56, MSE=28.325, abs fraction of change=0.000282\n",
      ">epoch=57, MSE=28.333, abs fraction of change=0.000279\n",
      ">epoch=58, MSE=28.340, abs fraction of change=0.000275\n",
      ">epoch=59, MSE=28.348, abs fraction of change=0.000271\n",
      ">epoch=60, MSE=28.356, abs fraction of change=0.000267\n",
      ">epoch=61, MSE=28.363, abs fraction of change=0.000264\n",
      ">epoch=62, MSE=28.371, abs fraction of change=0.000260\n",
      ">epoch=63, MSE=28.378, abs fraction of change=0.000257\n",
      ">epoch=64, MSE=28.385, abs fraction of change=0.000253\n",
      ">epoch=65, MSE=28.392, abs fraction of change=0.000250\n",
      ">epoch=66, MSE=28.399, abs fraction of change=0.000247\n",
      ">epoch=67, MSE=28.406, abs fraction of change=0.000243\n",
      ">epoch=68, MSE=28.413, abs fraction of change=0.000240\n",
      ">epoch=69, MSE=28.420, abs fraction of change=0.000237\n",
      ">epoch=70, MSE=28.426, abs fraction of change=0.000234\n",
      ">epoch=71, MSE=28.433, abs fraction of change=0.000230\n",
      ">epoch=72, MSE=28.439, abs fraction of change=0.000227\n",
      ">epoch=73, MSE=28.446, abs fraction of change=0.000224\n",
      ">epoch=74, MSE=28.452, abs fraction of change=0.000221\n",
      ">epoch=75, MSE=28.458, abs fraction of change=0.000218\n",
      ">epoch=76, MSE=28.464, abs fraction of change=0.000215\n",
      ">epoch=77, MSE=28.470, abs fraction of change=0.000212\n",
      ">epoch=78, MSE=28.476, abs fraction of change=0.000209\n",
      ">epoch=79, MSE=28.482, abs fraction of change=0.000207\n",
      ">epoch=80, MSE=28.488, abs fraction of change=0.000204\n",
      ">epoch=81, MSE=28.494, abs fraction of change=0.000201\n",
      ">epoch=82, MSE=28.499, abs fraction of change=0.000198\n",
      ">epoch=83, MSE=28.505, abs fraction of change=0.000196\n",
      ">epoch=84, MSE=28.510, abs fraction of change=0.000193\n",
      ">epoch=85, MSE=28.516, abs fraction of change=0.000190\n",
      ">epoch=86, MSE=28.521, abs fraction of change=0.000188\n",
      ">epoch=87, MSE=28.526, abs fraction of change=0.000185\n",
      ">epoch=88, MSE=28.532, abs fraction of change=0.000183\n",
      ">epoch=89, MSE=28.537, abs fraction of change=0.000180\n",
      ">epoch=90, MSE=28.542, abs fraction of change=0.000178\n",
      ">epoch=91, MSE=28.547, abs fraction of change=0.000175\n",
      ">epoch=92, MSE=28.552, abs fraction of change=0.000173\n",
      ">epoch=93, MSE=28.557, abs fraction of change=0.000171\n",
      ">epoch=94, MSE=28.561, abs fraction of change=0.000168\n",
      ">epoch=95, MSE=28.566, abs fraction of change=0.000166\n",
      ">epoch=96, MSE=28.571, abs fraction of change=0.000164\n",
      ">epoch=97, MSE=28.576, abs fraction of change=0.000162\n",
      ">epoch=98, MSE=28.580, abs fraction of change=0.000160\n",
      ">epoch=99, MSE=28.585, abs fraction of change=0.000157\n",
      ">epoch=100, MSE=28.589, abs fraction of change=0.000155\n",
      ">epoch=101, MSE=28.593, abs fraction of change=0.000153\n",
      ">epoch=102, MSE=28.598, abs fraction of change=0.000151\n",
      ">epoch=103, MSE=28.602, abs fraction of change=0.000149\n",
      ">epoch=104, MSE=28.606, abs fraction of change=0.000147\n",
      ">epoch=105, MSE=28.610, abs fraction of change=0.000145\n",
      ">epoch=106, MSE=28.614, abs fraction of change=0.000144\n",
      ">epoch=107, MSE=28.619, abs fraction of change=0.000142\n",
      ">epoch=108, MSE=28.623, abs fraction of change=0.000140\n",
      ">epoch=109, MSE=28.627, abs fraction of change=0.000138\n",
      ">epoch=110, MSE=28.630, abs fraction of change=0.000136\n",
      ">epoch=111, MSE=28.634, abs fraction of change=0.000135\n",
      ">epoch=112, MSE=28.638, abs fraction of change=0.000133\n",
      ">epoch=113, MSE=28.642, abs fraction of change=0.000131\n",
      ">epoch=114, MSE=28.646, abs fraction of change=0.000130\n",
      ">epoch=115, MSE=28.649, abs fraction of change=0.000128\n",
      ">epoch=116, MSE=28.653, abs fraction of change=0.000126\n",
      ">epoch=117, MSE=28.656, abs fraction of change=0.000125\n",
      ">epoch=118, MSE=28.660, abs fraction of change=0.000123\n",
      ">epoch=119, MSE=28.663, abs fraction of change=0.000122\n",
      ">epoch=120, MSE=28.667, abs fraction of change=0.000120\n",
      ">epoch=121, MSE=28.670, abs fraction of change=0.000119\n",
      ">epoch=122, MSE=28.674, abs fraction of change=0.000117\n",
      ">epoch=123, MSE=28.677, abs fraction of change=0.000116\n",
      ">epoch=124, MSE=28.680, abs fraction of change=0.000115\n",
      ">epoch=125, MSE=28.684, abs fraction of change=0.000113\n",
      ">epoch=126, MSE=28.687, abs fraction of change=0.000112\n",
      ">epoch=127, MSE=28.690, abs fraction of change=0.000111\n",
      ">epoch=128, MSE=28.693, abs fraction of change=0.000109\n",
      ">epoch=129, MSE=28.696, abs fraction of change=0.000108\n",
      ">epoch=130, MSE=28.699, abs fraction of change=0.000107\n",
      ">epoch=131, MSE=28.702, abs fraction of change=0.000106\n",
      ">epoch=132, MSE=28.705, abs fraction of change=0.000104\n",
      ">epoch=133, MSE=28.708, abs fraction of change=0.000103\n",
      ">epoch=134, MSE=28.711, abs fraction of change=0.000102\n",
      ">epoch=135, MSE=28.714, abs fraction of change=0.000101\n",
      "Epoch need:136\n"
     ]
    }
   ],
   "source": [
    "# normalize inputs\n",
    "\n",
    "minmax = dataset_minmax(trainingSet)\n",
    "normalize_data(trainingSet, minmax)\n",
    "\n",
    "learning_rate = 0.1\n",
    "n_epoch = 700\n",
    "n_hidden = 4\n",
    "scores = list()\n",
    "epoch = back_propagate(trainingSet, learning_rate, n_epoch, n_hidden)\n",
    "results.append(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- lrate=0.200 -----------------\n",
      ">epoch=0, MSE=40.268, abs fraction of change=0.000000\n",
      ">epoch=1, MSE=45.302, abs fraction of change=0.125024\n",
      ">epoch=2, MSE=45.476, abs fraction of change=0.003839\n",
      ">epoch=3, MSE=45.640, abs fraction of change=0.003597\n",
      ">epoch=4, MSE=45.796, abs fraction of change=0.003414\n",
      ">epoch=5, MSE=45.944, abs fraction of change=0.003230\n",
      ">epoch=6, MSE=46.084, abs fraction of change=0.003050\n",
      ">epoch=7, MSE=46.216, abs fraction of change=0.002874\n",
      ">epoch=8, MSE=46.341, abs fraction of change=0.002703\n",
      ">epoch=9, MSE=46.459, abs fraction of change=0.002538\n",
      ">epoch=10, MSE=46.569, abs fraction of change=0.002380\n",
      ">epoch=11, MSE=46.673, abs fraction of change=0.002229\n",
      ">epoch=12, MSE=46.770, abs fraction of change=0.002086\n",
      ">epoch=13, MSE=46.862, abs fraction of change=0.001951\n",
      ">epoch=14, MSE=46.947, abs fraction of change=0.001824\n",
      ">epoch=15, MSE=47.027, abs fraction of change=0.001706\n",
      ">epoch=16, MSE=47.102, abs fraction of change=0.001596\n",
      ">epoch=17, MSE=47.173, abs fraction of change=0.001494\n",
      ">epoch=18, MSE=47.239, abs fraction of change=0.001399\n",
      ">epoch=19, MSE=47.301, abs fraction of change=0.001311\n",
      ">epoch=20, MSE=47.359, abs fraction of change=0.001230\n",
      ">epoch=21, MSE=47.413, abs fraction of change=0.001154\n",
      ">epoch=22, MSE=47.465, abs fraction of change=0.001084\n",
      ">epoch=23, MSE=47.513, abs fraction of change=0.001019\n",
      ">epoch=24, MSE=47.559, abs fraction of change=0.000958\n",
      ">epoch=25, MSE=47.602, abs fraction of change=0.000902\n",
      ">epoch=26, MSE=47.642, abs fraction of change=0.000849\n",
      ">epoch=27, MSE=47.680, abs fraction of change=0.000800\n",
      ">epoch=28, MSE=47.716, abs fraction of change=0.000755\n",
      ">epoch=29, MSE=47.750, abs fraction of change=0.000713\n",
      ">epoch=30, MSE=47.782, abs fraction of change=0.000673\n",
      ">epoch=31, MSE=47.813, abs fraction of change=0.000637\n",
      ">epoch=32, MSE=47.842, abs fraction of change=0.000603\n",
      ">epoch=33, MSE=47.869, abs fraction of change=0.000571\n",
      ">epoch=34, MSE=47.895, abs fraction of change=0.000542\n",
      ">epoch=35, MSE=47.919, abs fraction of change=0.000514\n",
      ">epoch=36, MSE=47.943, abs fraction of change=0.000488\n",
      ">epoch=37, MSE=47.965, abs fraction of change=0.000465\n",
      ">epoch=38, MSE=47.986, abs fraction of change=0.000442\n",
      ">epoch=39, MSE=48.006, abs fraction of change=0.000421\n",
      ">epoch=40, MSE=48.026, abs fraction of change=0.000401\n",
      ">epoch=41, MSE=48.044, abs fraction of change=0.000383\n",
      ">epoch=42, MSE=48.062, abs fraction of change=0.000365\n",
      ">epoch=43, MSE=48.078, abs fraction of change=0.000349\n",
      ">epoch=44, MSE=48.094, abs fraction of change=0.000333\n",
      ">epoch=45, MSE=48.110, abs fraction of change=0.000319\n",
      ">epoch=46, MSE=48.124, abs fraction of change=0.000305\n",
      ">epoch=47, MSE=48.138, abs fraction of change=0.000292\n",
      ">epoch=48, MSE=48.152, abs fraction of change=0.000279\n",
      ">epoch=49, MSE=48.165, abs fraction of change=0.000268\n",
      ">epoch=50, MSE=48.177, abs fraction of change=0.000257\n",
      ">epoch=51, MSE=48.189, abs fraction of change=0.000246\n",
      ">epoch=52, MSE=48.200, abs fraction of change=0.000236\n",
      ">epoch=53, MSE=48.211, abs fraction of change=0.000227\n",
      ">epoch=54, MSE=48.222, abs fraction of change=0.000218\n",
      ">epoch=55, MSE=48.232, abs fraction of change=0.000210\n",
      ">epoch=56, MSE=48.242, abs fraction of change=0.000202\n",
      ">epoch=57, MSE=48.251, abs fraction of change=0.000194\n",
      ">epoch=58, MSE=48.260, abs fraction of change=0.000187\n",
      ">epoch=59, MSE=48.269, abs fraction of change=0.000180\n",
      ">epoch=60, MSE=48.277, abs fraction of change=0.000174\n",
      ">epoch=61, MSE=48.285, abs fraction of change=0.000168\n",
      ">epoch=62, MSE=48.293, abs fraction of change=0.000162\n",
      ">epoch=63, MSE=48.301, abs fraction of change=0.000156\n",
      ">epoch=64, MSE=48.308, abs fraction of change=0.000151\n",
      ">epoch=65, MSE=48.315, abs fraction of change=0.000146\n",
      ">epoch=66, MSE=48.322, abs fraction of change=0.000141\n",
      ">epoch=67, MSE=48.328, abs fraction of change=0.000137\n",
      ">epoch=68, MSE=48.335, abs fraction of change=0.000132\n",
      ">epoch=69, MSE=48.341, abs fraction of change=0.000128\n",
      ">epoch=70, MSE=48.347, abs fraction of change=0.000124\n",
      ">epoch=71, MSE=48.353, abs fraction of change=0.000120\n",
      ">epoch=72, MSE=48.359, abs fraction of change=0.000117\n",
      ">epoch=73, MSE=48.364, abs fraction of change=0.000113\n",
      ">epoch=74, MSE=48.369, abs fraction of change=0.000110\n",
      ">epoch=75, MSE=48.374, abs fraction of change=0.000106\n",
      ">epoch=76, MSE=48.379, abs fraction of change=0.000103\n",
      ">epoch=77, MSE=48.384, abs fraction of change=0.000100\n",
      "Epoch need:78\n"
     ]
    }
   ],
   "source": [
    "# normalize inputs\n",
    "dataset = list(lines)\n",
    "trainingSet = loadDataset(dataset) #reload data\n",
    "minmax = dataset_minmax(trainingSet)\n",
    "normalize_data(trainingSet, minmax)\n",
    "\n",
    "learning_rate = 0.2\n",
    "n_epoch = 300\n",
    "n_hidden = 4\n",
    "\n",
    "epoch = back_propagate(trainingSet, learning_rate, n_epoch, n_hidden)\n",
    "results.append(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- lrate=0.300 -----------------\n",
      ">epoch=0, MSE=53.000, abs fraction of change=0.000000\n",
      ">epoch=1, MSE=58.319, abs fraction of change=0.100343\n",
      ">epoch=2, MSE=58.899, abs fraction of change=0.009950\n",
      ">epoch=3, MSE=59.420, abs fraction of change=0.008853\n",
      ">epoch=4, MSE=59.880, abs fraction of change=0.007735\n",
      ">epoch=5, MSE=60.279, abs fraction of change=0.006669\n",
      ">epoch=6, MSE=60.623, abs fraction of change=0.005703\n",
      ">epoch=7, MSE=60.918, abs fraction of change=0.004861\n",
      ">epoch=8, MSE=61.170, abs fraction of change=0.004143\n",
      ">epoch=9, MSE=61.387, abs fraction of change=0.003540\n",
      ">epoch=10, MSE=61.573, abs fraction of change=0.003034\n",
      ">epoch=11, MSE=61.734, abs fraction of change=0.002612\n",
      ">epoch=12, MSE=61.873, abs fraction of change=0.002259\n",
      ">epoch=13, MSE=61.995, abs fraction of change=0.001964\n",
      ">epoch=14, MSE=62.101, abs fraction of change=0.001716\n",
      ">epoch=15, MSE=62.195, abs fraction of change=0.001508\n",
      ">epoch=16, MSE=62.278, abs fraction of change=0.001332\n",
      ">epoch=17, MSE=62.351, abs fraction of change=0.001182\n",
      ">epoch=18, MSE=62.417, abs fraction of change=0.001054\n",
      ">epoch=19, MSE=62.476, abs fraction of change=0.000944\n",
      ">epoch=20, MSE=62.529, abs fraction of change=0.000849\n",
      ">epoch=21, MSE=62.577, abs fraction of change=0.000766\n",
      ">epoch=22, MSE=62.620, abs fraction of change=0.000694\n",
      ">epoch=23, MSE=62.660, abs fraction of change=0.000630\n",
      ">epoch=24, MSE=62.696, abs fraction of change=0.000575\n",
      ">epoch=25, MSE=62.729, abs fraction of change=0.000525\n",
      ">epoch=26, MSE=62.759, abs fraction of change=0.000482\n",
      ">epoch=27, MSE=62.787, abs fraction of change=0.000443\n",
      ">epoch=28, MSE=62.812, abs fraction of change=0.000409\n",
      ">epoch=29, MSE=62.836, abs fraction of change=0.000378\n",
      ">epoch=30, MSE=62.858, abs fraction of change=0.000350\n",
      ">epoch=31, MSE=62.878, abs fraction of change=0.000325\n",
      ">epoch=32, MSE=62.898, abs fraction of change=0.000303\n",
      ">epoch=33, MSE=62.915, abs fraction of change=0.000283\n",
      ">epoch=34, MSE=62.932, abs fraction of change=0.000264\n",
      ">epoch=35, MSE=62.947, abs fraction of change=0.000247\n",
      ">epoch=36, MSE=62.962, abs fraction of change=0.000232\n",
      ">epoch=37, MSE=62.976, abs fraction of change=0.000218\n",
      ">epoch=38, MSE=62.989, abs fraction of change=0.000205\n",
      ">epoch=39, MSE=63.001, abs fraction of change=0.000193\n",
      ">epoch=40, MSE=63.012, abs fraction of change=0.000182\n",
      ">epoch=41, MSE=63.023, abs fraction of change=0.000172\n",
      ">epoch=42, MSE=63.034, abs fraction of change=0.000163\n",
      ">epoch=43, MSE=63.043, abs fraction of change=0.000155\n",
      ">epoch=44, MSE=63.053, abs fraction of change=0.000147\n",
      ">epoch=45, MSE=63.061, abs fraction of change=0.000139\n",
      ">epoch=46, MSE=63.070, abs fraction of change=0.000133\n",
      ">epoch=47, MSE=63.078, abs fraction of change=0.000126\n",
      ">epoch=48, MSE=63.085, abs fraction of change=0.000120\n",
      ">epoch=49, MSE=63.093, abs fraction of change=0.000115\n",
      ">epoch=50, MSE=63.099, abs fraction of change=0.000110\n",
      ">epoch=51, MSE=63.106, abs fraction of change=0.000105\n",
      ">epoch=52, MSE=63.112, abs fraction of change=0.000100\n",
      "Epoch need:53\n"
     ]
    }
   ],
   "source": [
    "# normalize inputs\n",
    "trainingSet = loadDataset(dataset) #reload data\n",
    "minmax = dataset_minmax(trainingSet)\n",
    "normalize_data(trainingSet, minmax)\n",
    "\n",
    "learning_rate = 0.3\n",
    "n_epoch = 300\n",
    "n_hidden = 4\n",
    "\n",
    "epoch = back_propagate(trainingSet, learning_rate, n_epoch, n_hidden)\n",
    "results.append(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- lrate=0.400 -----------------\n",
      ">epoch=0, MSE=64.185, abs fraction of change=0.000000\n",
      ">epoch=1, MSE=70.024, abs fraction of change=0.090962\n",
      ">epoch=2, MSE=71.122, abs fraction of change=0.015686\n",
      ">epoch=3, MSE=71.974, abs fraction of change=0.011980\n",
      ">epoch=4, MSE=72.621, abs fraction of change=0.008985\n",
      ">epoch=5, MSE=73.112, abs fraction of change=0.006758\n",
      ">epoch=6, MSE=73.487, abs fraction of change=0.005132\n",
      ">epoch=7, MSE=73.777, abs fraction of change=0.003944\n",
      ">epoch=8, MSE=74.004, abs fraction of change=0.003078\n",
      ">epoch=9, MSE=74.185, abs fraction of change=0.002446\n",
      ">epoch=10, MSE=74.332, abs fraction of change=0.001980\n",
      ">epoch=11, MSE=74.453, abs fraction of change=0.001629\n",
      ">epoch=12, MSE=74.554, abs fraction of change=0.001359\n",
      ">epoch=13, MSE=74.640, abs fraction of change=0.001147\n",
      ">epoch=14, MSE=74.712, abs fraction of change=0.000978\n",
      ">epoch=15, MSE=74.775, abs fraction of change=0.000841\n",
      ">epoch=16, MSE=74.830, abs fraction of change=0.000729\n",
      ">epoch=17, MSE=74.877, abs fraction of change=0.000637\n",
      ">epoch=18, MSE=74.920, abs fraction of change=0.000561\n",
      ">epoch=19, MSE=74.957, abs fraction of change=0.000497\n",
      ">epoch=20, MSE=74.990, abs fraction of change=0.000443\n",
      ">epoch=21, MSE=75.020, abs fraction of change=0.000397\n",
      ">epoch=22, MSE=75.046, abs fraction of change=0.000357\n",
      ">epoch=23, MSE=75.071, abs fraction of change=0.000323\n",
      ">epoch=24, MSE=75.093, abs fraction of change=0.000293\n",
      ">epoch=25, MSE=75.113, abs fraction of change=0.000266\n",
      ">epoch=26, MSE=75.131, abs fraction of change=0.000243\n",
      ">epoch=27, MSE=75.148, abs fraction of change=0.000223\n",
      ">epoch=28, MSE=75.163, abs fraction of change=0.000205\n",
      ">epoch=29, MSE=75.177, abs fraction of change=0.000189\n",
      ">epoch=30, MSE=75.190, abs fraction of change=0.000175\n",
      ">epoch=31, MSE=75.203, abs fraction of change=0.000162\n",
      ">epoch=32, MSE=75.214, abs fraction of change=0.000150\n",
      ">epoch=33, MSE=75.224, abs fraction of change=0.000140\n",
      ">epoch=34, MSE=75.234, abs fraction of change=0.000130\n",
      ">epoch=35, MSE=75.243, abs fraction of change=0.000122\n",
      ">epoch=36, MSE=75.252, abs fraction of change=0.000114\n",
      ">epoch=37, MSE=75.260, abs fraction of change=0.000107\n",
      ">epoch=38, MSE=75.268, abs fraction of change=0.000101\n",
      "Epoch need:39\n"
     ]
    }
   ],
   "source": [
    "# normalize inputs\n",
    "trainingSet = loadDataset(dataset) #reload data\n",
    "minmax = dataset_minmax(trainingSet)\n",
    "normalize_data(trainingSet, minmax)\n",
    "\n",
    "learning_rate = 0.4\n",
    "n_epoch = 300\n",
    "n_hidden = 4\n",
    "\n",
    "epoch = back_propagate(trainingSet, learning_rate, n_epoch, n_hidden)\n",
    "results.append(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- lrate=0.500 -----------------\n",
      ">epoch=0, MSE=74.106, abs fraction of change=0.000000\n",
      ">epoch=1, MSE=80.702, abs fraction of change=0.089004\n",
      ">epoch=2, MSE=82.266, abs fraction of change=0.019382\n",
      ">epoch=3, MSE=83.266, abs fraction of change=0.012155\n",
      ">epoch=4, MSE=83.915, abs fraction of change=0.007792\n",
      ">epoch=5, MSE=84.354, abs fraction of change=0.005230\n",
      ">epoch=6, MSE=84.662, abs fraction of change=0.003650\n",
      ">epoch=7, MSE=84.885, abs fraction of change=0.002640\n",
      ">epoch=8, MSE=85.053, abs fraction of change=0.001975\n",
      ">epoch=9, MSE=85.182, abs fraction of change=0.001521\n",
      ">epoch=10, MSE=85.285, abs fraction of change=0.001202\n",
      ">epoch=11, MSE=85.367, abs fraction of change=0.000969\n",
      ">epoch=12, MSE=85.435, abs fraction of change=0.000795\n",
      ">epoch=13, MSE=85.492, abs fraction of change=0.000662\n",
      ">epoch=14, MSE=85.539, abs fraction of change=0.000558\n",
      ">epoch=15, MSE=85.580, abs fraction of change=0.000477\n",
      ">epoch=16, MSE=85.615, abs fraction of change=0.000411\n",
      ">epoch=17, MSE=85.646, abs fraction of change=0.000357\n",
      ">epoch=18, MSE=85.673, abs fraction of change=0.000313\n",
      ">epoch=19, MSE=85.696, abs fraction of change=0.000277\n",
      ">epoch=20, MSE=85.718, abs fraction of change=0.000246\n",
      ">epoch=21, MSE=85.736, abs fraction of change=0.000220\n",
      ">epoch=22, MSE=85.753, abs fraction of change=0.000198\n",
      ">epoch=23, MSE=85.769, abs fraction of change=0.000178\n",
      ">epoch=24, MSE=85.782, abs fraction of change=0.000162\n",
      ">epoch=25, MSE=85.795, abs fraction of change=0.000147\n",
      ">epoch=26, MSE=85.807, abs fraction of change=0.000135\n",
      ">epoch=27, MSE=85.817, abs fraction of change=0.000123\n",
      ">epoch=28, MSE=85.827, abs fraction of change=0.000113\n",
      ">epoch=29, MSE=85.836, abs fraction of change=0.000105\n",
      "Epoch need:30\n"
     ]
    }
   ],
   "source": [
    "# normalize inputs\n",
    "trainingSet = loadDataset(dataset) #reload data\n",
    "minmax = dataset_minmax(trainingSet)\n",
    "normalize_data(trainingSet, minmax)\n",
    "\n",
    "learning_rate = 0.5\n",
    "n_epoch = 300\n",
    "n_hidden = 4\n",
    "\n",
    "epoch = back_propagate(trainingSet, learning_rate, n_epoch, n_hidden)\n",
    "results.append(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3X2clXP+x/HXpxtSK2oblUqFRMlNjdRa93IvrJDbEgqt3P1sLTY3bXLTsrlZclvJyrLLxrIkidXtdE/Y0oYUZaOQkvr8/vhes045M3Nm5pxznZnzfj4e12POuc65zvXes2Y+Xdf3ztwdERGRrdWIO4CIiOQmFQgREUlKBUJERJJSgRARkaRUIEREJCkVCBERSUoFQkREklKBEBGRpFQgREQkqVpxB6iMRo0aeatWreKOISJSpcyaNesLdy8o630ZKxBm9hhwIrDS3ffe6rX/A+4ECtz9CzMzYARwPLAO6O3us8s6R6tWrSgqKkp/eBGRaszMPkrlfZm8xTQKOHbrnWbWAugGfJyw+zigTbT1BR7IYC4REUlBxgqEu78JrE7y0t3Ab4DEWQJPBsZ4MA3Y0cyaZiqbiIiULauN1GbWHfjU3edt9VIz4JOE58uifSIiEpOsNVKbWV3geuDoZC8n2Zd0HnIz60u4DcUuu+yStnwiIrKlbF5B7Aa0BuaZ2VKgOTDbzJoQrhhaJLy3ObA82Ye4+0PuXujuhQUFZTbCi4hIBWWtQLj7Anffyd1buXsrQlHo6O6fAeOB8y3oAqxx9xXZyiYiIj+VsQJhZk8BU4G2ZrbMzC4s5e0vAUuAxcDDwGWZyiUiIqnJWBuEu59VxuutEh470D9TWX7i00/hzjvDVrt21k4rIlKV5OdUGzNmwIgRcPPNcScREclZ+VkgTj0VLrgAhg2Df/0r7jQiIjkpPwsEhCuIVq3gvPNg7dq404iI5Jz8LRDbbw9jx8LHH8OAAXGnERHJOflbIAC6doUbboDRo+GZZ+JOIyKSU/K7QEAoEJ07Q79+oXeTiIgAKhChm+vYsbBhA/TuDZs3x51IRCQnqEAAtGkDf/wjvPYa3HNP3GlERHKCCkSxiy6C7t1h0CBYsCDuNCIisVOBKGYGjzwCO+4I55wD69fHnUhEJFYqEIkKCuCxx8IVxPXXx51GRCRWKhBbO/54uOwyuOsumDgx7jQiIrFRgUjmzjuhbVvo1QtWJ1s1VUSk+lOBSKZuXXjySfj8c7jkEvCki9uJiFRrKhAl6dQJhgwJI6zHjo07jYhI1qlAlObaa+Hgg6F/f1i6NO40IiJZpQJRmpo1YcyY0AX2vPNg06a4E4mIZI0KRFlatYL77w/rRtxxR9xpRESyRgUiFeecA2eeCYMHQ1FR3GlERLJCBSIVZvDAA9CkSSgW334bdyIRkYxTgUhVgwZh3Yh//zs0XouIVHMqEOVxxBFwzTXhauIf/4g7jYhIRqlAlNfQodChA/TpAytXxp1GRCRjVCDKa9ttwyjrNWvCFOEaZS0i1ZQKREV06AC33QYvvAAPPxx3GhGRjFCBqKgBA+Coo+Cqq0LDtYhINaMCUVE1aoReTXXqwLnnwsaNcScSEUkrFYjK2HlnGDkSZs4ME/uJiFQjGSsQZvaYma00s3cS9t1pZu+b2Xwze87Mdkx47bdmttjMPjCzYzKVK+169IDevUPvpilT4k4jIpI2mbyCGAUcu9W+CcDe7r4P8G/gtwBm1g7oCbSPjvmTmdXMYLb0GjECWrYMt5rWro07jYhIWmSsQLj7m8Dqrfa96u4/RE+nAc2jxycD49x9g7v/B1gMdM5UtrSrXx+eeAI++giuuCLuNCIiaRFnG0Qf4OXocTPgk4TXlkX7qo6DDoLrroNRo+DZZ+NOIyJSabEUCDO7HvgBeLJ4V5K3JR2BZmZ9zazIzIpWrVqVqYgVM3gwFBZCv37w6adxpxERqZSsFwgz6wWcCJzj/r9hyMuAFglvaw4sT3a8uz/k7oXuXlhQUJDZsOVVu3YYZb1+PVxwAWzeHHciEZEKy2qBMLNjgYFAd3dfl/DSeKCnmW1rZq2BNsCMbGZLmz32gLvuggkT4N57404jIlJhmezm+hQwFWhrZsvM7ELgPmB7YIKZzTWzBwHc/V3gL8BC4J9Af3evuut79u0LJ54IAwfCO++U/X4RkRxkXoUnmyssLPSiXF3hbeXKMGdTkyYwY0aY5E9EJAeY2Sx3LyzrfRpJnSk77QSPPQbz58MNN8SdRkSk3FQgMumEE+DSS+EPf4DXX487jYhIuahAZNrw4aHhulcv+PLLuNOIiKRMBSLT6taFsWPhs8/gkku0wJCIVBkqENlQWAg33wx/+UsYJyEiUgWoQGTLwIFhOo7+/WHp0rjTiIiUSQUiW2rWDBP6ucP558OmqjvMQ0TygwpENrVuDffdB2+9BXfeGXcaEZFSqUBk23nnwemnw+9+B7Nnx51GRKREKhDZZgYPPhgG0p1zDqxbV/YxIiIxUIGIQ8OGMHo0vP8+/OY3cacREUlKBSIuRx0FV18N998PL70UdxoRkZ9QgYjT0KFhQr8+fSDXFj8SkbynAhGnOnXCwLkvv4SLLtIoaxHJKSoQcevQAW67DcaPh0ceiTuNiMj/qEDkgiuugCOPhCuvhEWL4k4jIgKoQOSGGjVg1KiwqNC558LGjXEnEhFRgcgZzZvDyJFh9bnf/z7uNCIiZRcIM7vCzOpb8KiZzTazo7MRLu+cfnqYp+n3v4epU+NOIyJ5LpUriD7uvhY4GigALgBuy2iqfHbvvbDLLuFW09dfx51GRPJYKgXCop/HA4+7+7yEfZJu9evDmDFhSvArr4w7jYjksVQKxCwze5VQIF4xs+2BzZmNlecOPhgGDYLHHoO//S3uNCKSp8zLGJxlZjWA/YAl7v6Vmf0caObu87MRsDSFhYVeVFQUd4zM2LgRfvELWLIEFiyAnXeOO5GIVBNmNsvdC8t6X5lXEO6+GfgcaGdmhwDtgR0rH1FKVbt2WMv6u+/gggtgsy7aRCS7apX1BjO7HTgTWAgUL4PmwJsZzCUAbdvCXXfBpZeGhYYGDIg7kYjkkTILBHAK0NbdN2Q6jCTRrx+8+GKYFvzII6F9+7gTiUieSKWReglQO9NBpARm8OijoXfTOefABtVpEcmOEq8gzOxewq2kdcBcM5sI/O+vk7vrfke2NG4cikT37mGp0jvuiDuRiOSB0m4xFXcPmgWMz0IWKc1JJ4XbTcOHw3HHweGHx51IRKq5VLq51gPWu/um6HlNYFt3L3UxZTN7DDgRWOnue0f7GgJPA62ApcAZ7v6lmRkwgjDWYh3Q291nlxW+WndzTebbb2H//UPPpvnzoUGDuBOJSBWUtm6uwERgu4Tn2wGvpXDcKODYrfYNAia6e5vocwdF+48D2kRbX+CBFD4//9SrFxYYWrEC+vePO42IVHOpFIg67v5N8ZPocd2yDnL3N4HVW+0+GRgdPR5N6CFVvH+MB9OAHc2saQrZ8s8BB8BNN8FTT8Gf/xx3GhGpxlIpEN+aWcfiJ2bWCfiugudr7O4rAKKfO0X7mwGfJLxvWbTvJ8ysr5kVmVnRqnxdx3nQoDDK+rLL4KOP4k4jItVUKgXiSuAZM3vLzN4itCH8Os05kk3+l7RxxN0fcvdCdy8sKChIc4wqolatMMp682bo1Qs2bSr7GBGRckplqo2ZwJ7ApcBlwF7uPquC5/u8+NZR9HNltH8Z0CLhfc2B5RU8R35o3TpMDT55cujZJCKSZqksGFSbUBxuAm4E+kX7KmI80Ct63Av4e8L+86NFiboAa4pvRUkpzj8fevQIYyNml9npS0SkXFK5xfQA0An4U7R1IoVeRmb2FDAVaGtmy8zsQsJCQ93MbBHQjR8XHnqJMGJ7MfAw4UpFymIGDz4IBQVhlPW6Unsei4iUSypzMR3g7vsmPH/dzOaVdZC7n1XCS0cmea8D6rdZET//OYwaBUcfDQMHhttOIiJpkMoVxCYz2634iZntyo+zukou6NYtrD53333w8stxpxGRaiKVK4hrgUlmtoTQ26glYV1qySXDhsGECdCnTxhlna89vEQkbVLpxTSRMMJ5QLS1dfdJmQ4m5VSnThhlvXo19O0LZUyhIiJSllR6MdUhtA/cBAwGLo32Sa7Zd1+49VZ4/vmwnrWISCWk0gYxhrDM6L3AfUA74IlMhpJKuOqqMNPrFVfA4sVxpxGRKiyVNoi2W/VimpRKLyaJSY0aMHo07LMPnHsu/OtfYeS1iEg5pXIFMScavAaAmR0IvJ25SFJpLVrAyJEwfToMHRp3GhGpolIpEAcCU8xsqZktJQx+O9TMFpjZ/Iymk4o74ww47zwYMgSmTYs7jYhUQance9h6TQepKu69F958M9xqmjMHtt8+7kQiUoWk0s31I8JEekdEj78Farj7R9FzyVU77ABPPAFLloTGaxGRckilm+uNwEDgt9GubYCxmQwlaXTwwWH9iEcfheeeizuNiFQhqbRBnAp0J1w54O7LAd2rqEpuugk6doSLLw7LlYqIpCCVAvF9NJmeA5hZvcxGkrTbZpswynrdOrjgAo2yFpGUpFIg/mJmIwnrRF8MvEaYkluqkj33DAsLvfIK3H9/3GlEpAowT+Ffk2bWDTiaMFnfK+4+IdPBUlFYWOhFRUVxx6g63OGEE2DSJJg1C9q1izuRiMTAzGa5e2FZ70tpiG1UEHKiKEglmIU5mjp0CAsMTZ8ebj+JiCSRyi0mqU6aNAk9mubOhcGD404jIjlMBSIfde8epgS/4w54442404hIjiqxQJjZxOjn7dmLI1lz112w++5w/vnw1VdxpxGRHFTaFURTMzsU6G5m+5tZx8QtWwElQ+rVg7FjYfly6K/lwEXkp0prpB4MDAKaA3dt9ZoDR2QqlGRJ585w442hLeKEE+Dss+NOJCI5pMxurmb2O3cfkqU85aJurmnwww9wyCGwcGFYy3qXXeJOJCIZlmo311Qm6xtiZt3NbHi0nZieiJITatUKE/pt2hTaIzZtijuRiOSIVCbrGwZcASyMtiuifVJd7LYb3HMPTJ4cGq9FREjtFtN8YD933xw9rwnMcfd9spCvVLrFlEbu0KMHvPACzJgB++0XdyIRyZC03WKK7JjweIeKRZKcZhaWKW3UKIyy/u67uBOJSMxSKRDDCOtSjzKz0cAs4NbMxpJYNGoEjz8eGqwHDYo7jYjELJVG6qeALsDfoq2ru4/LdDCJyTHHwIABoU3ilVfiTiMiMUrpFpO7r3D38e7+d3f/rLInNbOrzOxdM3vHzJ4yszpm1trMppvZIjN72sw0i1xcbrsN2reH3r3hiy/iTiMiMcn6XExm1gwYABS6+95ATaAncDtwt7u3Ab4ELsx2Nolst11YYGj16rAKnRYYEslLcU3WVwvYzsxqAXWBFYSR2c9Gr48GTokpmwDsuy8MHQrPPx/aJUQk75RaIMyshpm9k84TuvunwHDgY0JhWENo+P7K3X+I3rYMaJbO80oFXH01HH54aJP48MO404hIlpVaIKKxD/PMLG3zL5hZA+BkoDWwM1APOC7Z6Us4vq+ZFZlZ0apVq9IVS5KpUQNGjw6jrc89FzZsiDuRiGRRKreYmgLvmtlEMxtfvFXinEcB/3H3Ve6+kdAz6heENa+LJw9sDixPdrC7P+Tuhe5eWFBQUIkYkpIWLeDBB2HatHDb6fXX404kIlmSypKjN6f5nB8DXcysLvAdcCRQBEwCegDjgF7A39N8Xqmonj2hQYMwLfiRR4ZZX//wh7A6nYhUW6mMg5gMLAVqR49nArMrekJ3n05ojJ4NLIgyPAQMBK42s8XAz4FHK3oOyYBjjoEFC8LU4M8+C3vuCfffr8n9RKqxVOZiuhjoCzR0993MrA3woLsfmY2ApdFcTDH597/D1cRrr0GnTuEWVGGZ07qISI5I51xM/YGDgLUA7r4I2Kly8aRK22MPePVVGDcurEjXuTP8+tdaulSkmkmlQGxw9++Ln0QNyRo5le/M4Mwz4b334PLL4YEHwm2nJ5/UwDqRaiKVAjHZzK4jDGzrBjwDvJDZWFJl7LADjBgBM2dCy5ahO+xRR8H778edTEQqKZUCMQhYRWhQ7ge8BNyQyVBSBXXsCFOmhCuJ2bNhn33g+uth3bq4k4lIBaXSi2kzYeqLIYQur6O9rJZtyU81a8Ill4Srh5494dZbw6R///hH3MlEpAJSWXL0BOBD4B7gPmCxmSUb+SwSNG4MY8bAG2+Eif9OPBF+9Sv45JO4k4lIOaRyi+kPwOHufpi7HwocDtyd2VhSLRx6KMydC8OGwT//CXvtBcOHw8aNcScTkRSkUiBWuvvihOdLgJUZyiPVzTbbhNXpFi6EI46Aa68N7RVvvx13MhEpQ4kFwsx+ZWa/IszD9JKZ9TazXoQeTDOzllCqh1atYPz4MH342rXwy19Cnz5akEgkh5V2BXFStNUBPgcOBQ4j9GhqkPFkUj2dfHK4mhg4EJ54Atq2hUcegc2b404mIlspc6qNXKapNqq4d9+Fyy6DN9+Erl3DlB377BN3KpFqL21TbURrRd9lZn9L03TfIkH79qGn06hRsGhRaJu45hr4+uu4k4kIqTVSP0+YzfVeQo+m4k2k8sygVy/44AO46CK4++7Q2+nZZzVlh0jMUikQ6939Hnef5O6Ti7eMJ5P80rBhuMU0ZQoUFMDpp8Pxx2upU5EYpVIgRpjZjWbW1cw6Fm8ZTyb5qUuXMK/TH/8YusLuvTcMGaLlTkVikEqB6ABcDNzGj7eXhmcylOS5WrXgiivCTLHdu4dFijp0COtPiEjWpFIgTgV2dfdD3f3waDsi08FEaNYMnn4aXnkltEd06wZnnQUrVsSdTCQvpFIg5gE7ZjqISImOPjosd3rTTfDcc2HdiXvv1XKnIhmWSoFoDLxvZq+om6vEpk4duPHGUCi6dIEBA8JKdjM1qF8kU2ql8J4bM55CJFVt2oSJ/555Bq68Eg48MEwxPnQoNNAAf5F0SmU9iMnJtmyEE0nKDM44I6w7MWAAjBwZbjs98YTGToikUSojqb82s7XRtt7MNpnZ2myEEylV/fqhO2xREbRuDeefH2aMfe+9uJOJVAupXEFs7+71o60OcBph4SCR3LD//mGA3ciRMG8e7LsvXHedljsVqaRUGqm34O7PA+rmKrmlRg3o2zfcdjr77LBIUfv28OKLcScTqbJSucX0q4Sth5ndBuhGr+SmnXYKk/9Nngx168JJJ8Gpp8LHH8edTKTKSeUK4qSE7Rjga+DkTIYSqbRDDoE5c+C22+DVV8MEgHfcoeVORcpB60FI9ffRR2Hqjr//Pdx2euABOPjguFOJxCbV9SBKHAdhZoNLOc7dfUiFkolkW8uWYanTF16Ayy8PVxe9e4crioKCuNOJ5KzSbjF9m2QDuBAYWJmTmtmOZvasmb1vZu9FM8U2NLMJZrYo+qlRT5JeJ50UVrEbNAjGjg3LnT78sJY7FSlBiQXC3f9QvAEPAdsBFwDjgF0red4RwD/dfU9gX+A9YBAw0d3bABOj5yLpVa9e6OE0b15Y3rRvXzjoIJg7N+5kIjmn1Ebq6F/1vwfmE25HdXT3ge6+sqInNLP6wCHAowDu/r27f0Vo+B4dvW00cEpFzyFSpnbtYNIkGD06LErUqRNcdZWWOxVJUGKBMLM7gZmEXksd3P0md/8yDefcFVgFPG5mc8zsETOrBzR29xUA0c+d0nAukZKZhdHXH3wQriRGjAhTdjzzjKbsEKH0K4hrgJ2BG4DlCdNtfF3JqTZqAR2BB9x9f0LbRsq3k8ysr5kVmVnRqlWrKhFDJNKgQejZNHUqNG4c5nk67jhYvDjuZCKxKq0Nooa7b7fVVBv1i59X4pzLgGXuPj16/iyhYHxuZk0Bop9Jb2O5+0PuXujuhQXqgSLpdOCBMGNGuJKYMiUsd3rLLbB+fdzJRGJR7qk2KsvdPwM+MbO20a4jgYXAeKBXtK8X8PdsZxOhVq0wQ+wHH4QR2DfeGBqzJ0yIO5lI1mW9QEQuB540s/nAfsCthDWvu5nZIqBb9FwkHk2bwlNPhVHYEFa169kTli+PN5dIFmkktUhZ1q8Pg+puvRW22QaGDIH+/cPVhkgVlOpI6riuIESqjjp1YPBgeOcd+MUvwkp2nTvD9OllHytShalAiKRq993h5ZdDN9jPP4euXcNyp1+mo/e3SO5RgRApDzPo0SOsO3HllfDII2HKjjFjNHZCqh0VCJGK2H57uOsumDULdtsNevWCww+HhQvjTiaSNioQIpWx777w9tvw0EMwf354PmgQfPtt2ceK5DgVCJHKqlEDLr44jJ0491y4/fYw19Mdd4S1KESqKBUIkXQpKIDHH4c334RmzWDgQGjVKvR8uuceWLEi7oQi5aICIZJuBx8cpur48MMwtfi6dWFFu2bN4Igjwu2oL76IO6VImVQgRDJl111De8TcuaHxevDgMBK7Xz9o0iRMCDh6NKxZE3dSkaRUIESyYa+94Kab4L33QsG49trQVbZ3b9hpJzjlFBg3To3bklNUIESyySz0dBo2DJYsgWnT4LLLYOZMOOusUCx69gxraGsWWYmZCoRIXMzCFON33w2ffAKTJ4fxFBMnhplkGzcOVxgvvwwbN8adVvKQCoRILqhRAw45BP70p9Db6ZVX4LTTwpXE8ceH2WX79QvLpG7aFHdayRMqECK5platML34Y4+FOZ/Gj4djjoEnnwy9oJo3D72ipkyBzZvjTivVmAqESC7bdls46aRQHFauhL/8JYyrGDkSDjoIWreG3/wGZs/WXFCSdioQIlVF3bpw+unw17+GYjFmDHToENowOnUKkwYOHqz5oCRtVCBEqqL69eG88+DFF8NtqIcfhl12gaFDoX37UDiGDoXFi+NOKlWYCoRIVdewIVx0Ebz2WhiId999sOOOcMMN0KYNHHAADB8OH38cd1KpYlQgRKqTxo3DcqhvvRUKwvDhYf+110LLlvDLX4YC8tln8eaUKkEFQqS6atECrrkmDMJbtCjcclq7Fi6/PMwLddRRYcGj1avjTio5SgVCJB/svjtcd11Ys+Kdd+D668MVxsUXh6uOE06AJ54IBUQkogIhkm/at4dbbgnrV8yaBVddFYrG+eeHqT5OOy2su71uXdxJJWYqECL5ygw6dgwLG/3nP2HgXb9+4ecZZ4RicfbZYaDehg1xp5UYqECISJjqo2tXGDECli2D11+Hc86BV1+Fk08Ot6H69AlTgGheqLyhAiEiW6pZEw4/PIzWXrEiTBZ4yilhgN6xx8LOO8Oll4bJBTUvVLWmAiEiJatdOxSFUaPCgLznnoMjjwyjuA87LAzOu+oqmD5dU31UQyoQIpKaOnV+XNho5crws3PnMANtly5brqCnYlEtqECISPnVqwdnnhmuKFauDFcYe+0VBubtv/+WK+hJlRVbgTCzmmY2x8xejJ63NrPpZrbIzJ42s23iyiYi5bDDDmGho5deCiO0R44M7RS33ALt2m25gp5UKXFeQVwBJP7z4nbgbndvA3wJXBhLKhGpuEaNoG/f0Avq009Dr6h69cIgvd12+3EFvU8/jTuppCCWAmFmzYETgEei5wYcATwbvWU0cEoc2UQkTZo2hQEDwriKpUvDeIsffoCrrw7TgBx6aGi/WLky7qRSgriuIP4I/AYoXg7r58BX7v5D9HwZ0CyOYCKSAS1bhgkDZ80KI7hvvhlWrQoTCzZtCt26hQLy1lsawZ1Dsl4gzOxEYKW7z0rcneStSbtBmFlfMysys6JVq1ZlJKOIZNAee8Dvfgfvvhvmhvrtb+GTT2DgwLAu9w47QGEh/PrXYSW9Dz9Ur6iYmGf5izezYcB5wA9AHaA+8BxwDNDE3X8ws67ATe5+TGmfVVhY6EVFRZmOLCLZsGpVGE8xbRpMnQozZsA334TXCgpCV9quXcPPAw6An/0s3rxVmJnNcvfCMt+X7QKxxcnNDgP+z91PNLNngL+6+zgzexCY7+5/Ku14FQiRamzTpnCVUVwwpk2D998Pr9WoEVbNKy4YXbuGxZEs2c0I2VpVLBC7AuOAhsAc4Fx3L3WGMBUIkTyzenW4siguGNOnw5o14bWGDUMvqeKi0blzuF0lP1ElCkRlqUCI5LnNm8NVRXHBmDoVFi4MbRZmYRxG4lXGnnuGq488pwIhIvlpzZpwlTFt2o9b8ap59etveZVx4IHhyiPPqECIiEC4mli0aMurjAULwtUHQNu2W15ltG8fZrStxlQgRERK8s03Ya3uxAbw4m7zP/tZaL8oLhgHHhh6UVUjKhAiIqlyD3NFFd+SmjoV5s0LI78hrOndpcuPRaNDhzAVehWlAiEiUhnr1oWR38UFY+rUMBkhwHbbhbEYiWMzmjSJN285qECIiKSTO3z88Za3pWbP/nEJ1lattrzK2G8/2CY3J6VWgRARybT162HOnC0bwJctC69tuy106rTlVUbz5vHmjahAiIjEYdmyLbvYFhXBhmjMb/PmWxaMjh3DSn1ZpgIhIpILvv8+NHgnXmUsXRpeq107rMBXXDC6dAkz32Z4yhAVCBGRXPXZZ1v2mJo5E777LrzWpMmWVxmFhVC3blpPrwIhIlJVbNwYBu8lFo3Fi8NrNWuGZVsTB/PtumulrjJUIEREqrIvvtiyYCROf96oEQwaBNdcU6GPTrVA1KrQp4uISGY1agQnnhg2+On0580yv+imCoSISFVQsybss0/Y+vbNyik1762IiCSlAiEiIkmpQIiISFIqECIikpQKhIiIJKUCISIiSalAiIhIUioQIiKSVJWeasPMVgEfVfDwRsAXaYyTLrmaC3I3m3KVj3KVT3XM1dLdy1xou0oXiMows6JU5iLJtlzNBbmbTbnKR7nKJ59z6RaTiIgkpQIhIiJJ5XOBeCjuACXI1VyQu9mUq3yUq3zyNlfetkGIiEjp8vkKQkRESlEtC4SZHWtmH5jZYjMblOT1Q8xstpn9YGY9tnqtl5ktirZeOZRrk5nNjbbxWc51tZktNLP5ZjbRzFomvBbn91Varji/r0vMbEF07n+ZWbuE134bHfeBmR2TC7nMrJWZfZfwfT2YzVwJ7+vjmfN4AAAGQ0lEQVRhZm5mhQn7Yvu+SsoV9/dlZr3NbFXC+S9KeC29v4/uXq02oCbwIbArsA0wD2i31XtaAfsAY4AeCfsbAkuinw2ixw3izhW99k2M39fhQN3o8aXA0znyfSXNlQPfV/2Ex92Bf0aP20Xv3xZoHX1OzRzI1Qp4J67vK3rf9sCbwDSgMBe+r1Jyxfp9Ab2B+5Icm/bfx+p4BdEZWOzuS9z9e2AccHLiG9x9qbvPBzZvdewxwAR3X+3uXwITgGNzIFcmpZJrkruvi55OA5pHj+P+vkrKlUmp5Fqb8LQeUNzQdzIwzt03uPt/gMXR58WdK5PKzBUZAtwBrE/YF+v3VUquTEo1VzJp/32sjgWiGfBJwvNl0b5MH5vpz65jZkVmNs3MTklTporkuhB4uYLHZisXxPx9mVl/M/uQ8MdlQHmOjSEXQGszm2Nmk83s4DRlSimXme0PtHD3F8t7bEy5IMbvK3JadGv1WTNrUc5jU1Yd16S2JPtS/ZdSZY7N9Gfv4u7LzWxX4HUzW+DuH2Yzl5mdCxQCh5b32Czngpi/L3e/H7jfzM4GbgB6pXpsDLlWEL6v/5pZJ+B5M2u/1RVHRnKZWQ3gbsJtk3IdW0mVyRXb9xV5AXjK3TeY2SXAaOCIFI8tl+p4BbEMaJHwvDmwPAvHZvSz3X159HMJ8AawfzZzmdlRwPVAd3ffUJ5jY8gV+/eVYBxQfAUT+/eVLFd0C+e/0eNZhHvge2Qp1/bA3sAbZrYU6AKMjxqE4/y+SswV8/eFu/834b/1h4FOqR5bbploaIlzI1wVLSE0ahU38rQv4b2j+Gkj9X8IDTwNoscNcyBXA2Db6HEjYBFJGtQylYvwx/VDoM1W+2P9vkrJFff31Sbh8UlAUfS4PVs2ui4hfY2ulclVUJyD0Dj6aRz/3Ufvf4MfG4Nj/b5KyRXr9wU0TXh8KjAtepz238dK/w/KxQ04Hvh39Mfj+mjfLYR/ZQIcQKi23wL/Bd5NOLYPoTFsMXBBLuQCfgEsiP5jWQBcmOVcrwGfA3OjbXyOfF9Jc+XA9zUCeDfKNCnxF5xwtfMh8AFwXC7kAk6L9s8DZgMnZTPXVu99g+gPcdzfV0m54v6+gGEJ558E7JlwbFp/HzWSWkREkqqObRAiIpIGKhAiIpKUCoSIiCSlAiEiIkmpQIiISFIqEFItmdk3WT7fI4mztmbpnFeaWd1snlPyi7q5SrVkZt+4+8/S+Hm13P2HdH1eiuc0wu9o0skboxG+he7+RTZzSf7QFYTkDTMrMLO/mtnMaDso2t/ZzKZEk69NMbO20f7eZvaMmb0AvGpmh5nZG9EEae+b2ZPRH3Gi/cXrBXxjZkPNbF40WWDjaP9u0fOZZnZLsqucaK2B98zsT4RBWC3M7IFo4sF3zezm6H0DgJ2BSWY2Kdp3tJlNtbCmyDNmlrYCKXkqnSMAtWnLlY0k60EAfwZ+GT3eBXgvelwfqBU9Pgr4a/S4N2Fke8Po+WHAGsIcNzWAqQmf9wY/jrR1otG1hFlTb4gevwicFT2+pISMrQjTvXdJ2Fd8/prRefaJni8FGkWPGxHWLagXPR8IDI77/wdtVXurjrO5ipTkKKBd9I9+gPpmtj2wAzDazNoQ/rjXTjhmgruvTng+w92XAZjZXMIf9H9tdZ7vCcUAYBbQLXrclR8n7vszMLyEnB+5+7SE52eYWV/CPD1NCQvpzN/qmC7R/rej/33bEAqYSIWpQEg+qQF0dffvEnea2b3AJHc/1cxaEf6VXuzbrT5jQ8LjTST/Hdro7l7Ge0rzv3OaWWvg/4AD3P1LMxsF1ElyjBGK2VnlPJdIidQGIfnkVeDXxU/MbL/o4Q6EGTkh+fz/6TKNMNEbQM8Uj6lPKBhroraM4xJe+5owLXXxZx9kZrsDmFldM0vXFNSSp1QgpLqqa2bLErarCSuoFUYrcS0ktANAaCcYZmZvE+7zZ8qVwNVmNoNwq2hNWQe4+zxgDmH2zseAtxNefgh42cwmufsqQnF7yszmEwrGnumNL/lG3VxFsiQas/Cdu7uZ9SQ0WKe63rBI1qkNQiR7OgH3RV1jvyLM3S+Ss3QFISIiSakNQkREklKBEBGRpFQgREQkKRUIERFJSgVCRESSUoEQEZGk/h+8RAveuf6LJwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([0.1, 0.2, 0.3, 0.4, 0.5], results, 'r')\n",
    "plt.xlabel(\"Learning rate\")\n",
    "plt.ylabel(\"Number of epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
