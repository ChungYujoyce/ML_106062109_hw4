{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from math import exp\n",
    "import matplotlib.pyplot as plt\n",
    "# process data label as 0, 1, 2 for training\n",
    "def loadDataset(dataset): \n",
    "    newdata = []\n",
    "    for x in range(len(dataset)-1):\n",
    "        for i in range(0,len(dataset[x]),4):\n",
    "            if dataset[x][i] == \"I\": # encounter labels, change it\n",
    "                if dataset[x][-3:-1] == \"sa\": # Iris-setosa\n",
    "                    newdata.append(0)\n",
    "                elif dataset[x][-2:-1] == \"r\": # Iris-versicolor\n",
    "                    newdata.append(1)\n",
    "                elif dataset[x][-3:-1] == \"ca\": # Iris-virginica\n",
    "                    newdata.append(2) \n",
    "                break\n",
    "            else:\n",
    "                attribute = float(dataset[x][i:i+3])\n",
    "                newdata.append(attribute)\n",
    "        trainingSet.append(newdata)       \n",
    "        newdata = [] # clear the package\n",
    "    return trainingSet\n",
    "\n",
    "# find the range of data to do normalize\n",
    "def dataset_minmax(dataset): # zip a(1,2,3) , b(4,5,6) to [(1,4), (2,5), (3,6)] \n",
    "    minmax = list()\n",
    "    stats = [[min(column), max(column)] for column in zip(*dataset)] # unzip the file\n",
    "    return stats\n",
    "\n",
    "# rescale data to range 0~1\n",
    "def normalize_data(dataset, minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row)-1):\n",
    "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "\n",
    "# calculate neuron activation for an input\n",
    "def activate(weights, inputs):\n",
    "    activation = weights[-1]\n",
    "    for i in range(len(weights)-1):\n",
    "        activation += weights[i] * inputs[i]\n",
    "    return activation\n",
    "\n",
    "# transfer neuron activation \n",
    "def transfer(activation):\n",
    "    return 1.0 / (1.0 + exp(-activation))\n",
    "\n",
    "# calculate the derivative of an neuron output\n",
    "def transfer_derivative(output):\n",
    "    return output * (1.0 - output)\n",
    "\n",
    "#forward propagate input to a network output\n",
    "def forward_propagate(network, row):\n",
    "    inputs = row\n",
    "    for layer in network:\n",
    "        new_inputs = []\n",
    "        for neuron in layer:\n",
    "            activation = activate(neuron['weights'], inputs)\n",
    "            neuron['output'] = transfer(activation)\n",
    "            new_inputs.append(neuron['output'])\n",
    "        inputs = new_inputs # keep updating the neurons\n",
    "    return inputs\n",
    "\n",
    "# backpropagate error and sotre in neurons\n",
    "def backward_propagate_error(network, expected): \n",
    "    for i in reversed(range(len(network))):\n",
    "        layer = network[i]\n",
    "        errors = list()\n",
    "        if i != len(network)-1:\n",
    "            for j in range(len(layer)): # hidden\n",
    "                error = 0.0\n",
    "                for neuron in network[i+1]:\n",
    "                    error += (neuron['weights'][j] * neuron['delta'])\n",
    "                errors.append(error) \n",
    "        else:\n",
    "            for j in range(len(layer)): # output\n",
    "                neuron = layer[j]\n",
    "                errors.append(expected[j] - neuron['output'])\n",
    "        for j in range(len(layer)):\n",
    "            neuron = layer[j]\n",
    "            neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
    "\n",
    "# update network weights with error\n",
    "def update_weights(network, row, learning_rate):\n",
    "    for i in range(len(network)):\n",
    "        inputs = row[:-1]\n",
    "        if i != 0:\n",
    "            inputs = [neuron['output'] for neuron in network[i-1]]\n",
    "        for neuron in network[i]:\n",
    "            for j in range(len(inputs)):\n",
    "                neuron['weights'][j] += learning_rate * neuron['delta'] * inputs[j]\n",
    "            neuron['weights'][-1] += learning_rate * neuron['delta']\n",
    "\n",
    "def train_network(network, train, learning_rate, n_epoch, n_outputs):\n",
    "    print(\"--------------- lrate=%.3f\" % learning_rate ,\"-----------------\")\n",
    "    prev_MSE = 0\n",
    "    MSE = 0\n",
    "    abs_fraction_of_change = 0\n",
    "    for epoch in range(n_epoch):\n",
    "        MSE = 0\n",
    "        for row in train:\n",
    "            outputs = forward_propagate(network, row)\n",
    "            expected = [0 for i in range(n_outputs)]\n",
    "            expected[row[-1]] = 1 # one hot encoding !!!\n",
    "            backward_propagate_error(network, expected)\n",
    "            update_weights(network, row, learning_rate)\n",
    "            update_outputs = forward_propagate(network, row) # update forward results\n",
    "            MSE += sum([(expected[i] - update_outputs[i])**2 for i in range(len(expected))])\n",
    "            #print(MSE)\n",
    "        MSE /= len(expected)\n",
    "        if epoch > 0:\n",
    "            abs_fraction_of_change = abs((MSE - prev_MSE) / prev_MSE )\n",
    "            if abs_fraction_of_change <= 10e-5:\n",
    "                print(\"Epoch need:%d\"%(epoch+1))\n",
    "                break\n",
    "        print('>epoch=%d, MSE=%.3f, abs fraction of change=%.6f' % (epoch, MSE, abs_fraction_of_change))\n",
    "        prev_MSE = MSE\n",
    "        #print(\"prev\",prev_MSE)\n",
    "    return (epoch+1)\n",
    "    \n",
    "    \n",
    "\n",
    "def init_network(n_inputs, n_hidden, n_outputs): \n",
    "# create n_hidden neurons and each neuron in the hidden layer has n_inputs + 1 weights\n",
    "    network = list()\n",
    "    hidden_layer1 = [{'weights': [(random.random()-0.5)/5.0 for i in range(n_inputs)]} for i in range(n_hidden)]\n",
    "    network.append(hidden_layer1) \n",
    "    hidden_layer2 = [{'weights': [(random.random()-0.5)/5.0 for i in range(n_inputs)]} for i in range(n_hidden)]\n",
    "    network.append(hidden_layer2)\n",
    "    output_layer = [{'weights': [(random.random()-0.5)/5.0 for i in range(n_hidden)]} for i in range(n_outputs)]\n",
    "    network.append(output_layer) \n",
    "    #for i in network:\n",
    "     #   print(i)\n",
    "    return network\n",
    "\n",
    "# make a prediction with a network\n",
    "# It returns the index in the network output that has the largest probability. \n",
    "# Assuming that class values have been converted to integers starting at 0. [0,1,2]\n",
    "def predict(network, row):\n",
    "    outputs = forward_propagate(network, row)\n",
    "    return outputs.index(max(outputs))\n",
    "\n",
    "# backpropagation with stochastic gradient descent\n",
    "def back_propagate(train, learning_rate, n_epoch, n_hidden):\n",
    "    n_inputs = len(train[0]) - 1\n",
    "    n_outputs = len(set([row[-1] for row in train]))\n",
    "    network = init_network(n_inputs, n_hidden, n_outputs)\n",
    "    epoch = train_network(network, train, learning_rate, n_epoch, n_outputs)\n",
    "    return epoch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet=[]\n",
    "testSet=[]\n",
    "results = []\n",
    "f = open('iris.data.txt', \"r\")\n",
    "lines = f.readlines()\n",
    "dataset = list(lines)\n",
    "trainingSet = loadDataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- lrate=0.100 -----------------\n",
      ">epoch=0, MSE=29.742, abs fraction of change=0.000000\n",
      ">epoch=1, MSE=30.866, abs fraction of change=0.037813\n",
      ">epoch=2, MSE=31.293, abs fraction of change=0.013828\n",
      ">epoch=3, MSE=31.389, abs fraction of change=0.003045\n",
      ">epoch=4, MSE=31.418, abs fraction of change=0.000924\n",
      ">epoch=5, MSE=31.433, abs fraction of change=0.000500\n",
      ">epoch=6, MSE=31.446, abs fraction of change=0.000414\n",
      ">epoch=7, MSE=31.459, abs fraction of change=0.000395\n",
      ">epoch=8, MSE=31.471, abs fraction of change=0.000389\n",
      ">epoch=9, MSE=31.483, abs fraction of change=0.000386\n",
      ">epoch=10, MSE=31.495, abs fraction of change=0.000384\n",
      ">epoch=11, MSE=31.507, abs fraction of change=0.000382\n",
      ">epoch=12, MSE=31.519, abs fraction of change=0.000380\n",
      ">epoch=13, MSE=31.531, abs fraction of change=0.000377\n",
      ">epoch=14, MSE=31.543, abs fraction of change=0.000375\n",
      ">epoch=15, MSE=31.555, abs fraction of change=0.000373\n",
      ">epoch=16, MSE=31.566, abs fraction of change=0.000370\n",
      ">epoch=17, MSE=31.578, abs fraction of change=0.000368\n",
      ">epoch=18, MSE=31.590, abs fraction of change=0.000365\n",
      ">epoch=19, MSE=31.601, abs fraction of change=0.000363\n",
      ">epoch=20, MSE=31.612, abs fraction of change=0.000360\n",
      ">epoch=21, MSE=31.624, abs fraction of change=0.000357\n",
      ">epoch=22, MSE=31.635, abs fraction of change=0.000355\n",
      ">epoch=23, MSE=31.646, abs fraction of change=0.000352\n",
      ">epoch=24, MSE=31.657, abs fraction of change=0.000349\n",
      ">epoch=25, MSE=31.668, abs fraction of change=0.000346\n",
      ">epoch=26, MSE=31.679, abs fraction of change=0.000343\n",
      ">epoch=27, MSE=31.690, abs fraction of change=0.000341\n",
      ">epoch=28, MSE=31.700, abs fraction of change=0.000338\n",
      ">epoch=29, MSE=31.711, abs fraction of change=0.000335\n",
      ">epoch=30, MSE=31.722, abs fraction of change=0.000332\n",
      ">epoch=31, MSE=31.732, abs fraction of change=0.000329\n",
      ">epoch=32, MSE=31.742, abs fraction of change=0.000326\n",
      ">epoch=33, MSE=31.753, abs fraction of change=0.000323\n",
      ">epoch=34, MSE=31.763, abs fraction of change=0.000320\n",
      ">epoch=35, MSE=31.773, abs fraction of change=0.000317\n",
      ">epoch=36, MSE=31.783, abs fraction of change=0.000314\n",
      ">epoch=37, MSE=31.793, abs fraction of change=0.000311\n",
      ">epoch=38, MSE=31.802, abs fraction of change=0.000308\n",
      ">epoch=39, MSE=31.812, abs fraction of change=0.000305\n",
      ">epoch=40, MSE=31.822, abs fraction of change=0.000302\n",
      ">epoch=41, MSE=31.831, abs fraction of change=0.000299\n",
      ">epoch=42, MSE=31.841, abs fraction of change=0.000296\n",
      ">epoch=43, MSE=31.850, abs fraction of change=0.000293\n",
      ">epoch=44, MSE=31.859, abs fraction of change=0.000290\n",
      ">epoch=45, MSE=31.868, abs fraction of change=0.000287\n",
      ">epoch=46, MSE=31.877, abs fraction of change=0.000284\n",
      ">epoch=47, MSE=31.886, abs fraction of change=0.000281\n",
      ">epoch=48, MSE=31.895, abs fraction of change=0.000278\n",
      ">epoch=49, MSE=31.904, abs fraction of change=0.000275\n",
      ">epoch=50, MSE=31.913, abs fraction of change=0.000272\n",
      ">epoch=51, MSE=31.921, abs fraction of change=0.000269\n",
      ">epoch=52, MSE=31.930, abs fraction of change=0.000266\n",
      ">epoch=53, MSE=31.938, abs fraction of change=0.000263\n",
      ">epoch=54, MSE=31.946, abs fraction of change=0.000260\n",
      ">epoch=55, MSE=31.955, abs fraction of change=0.000258\n",
      ">epoch=56, MSE=31.963, abs fraction of change=0.000255\n",
      ">epoch=57, MSE=31.971, abs fraction of change=0.000252\n",
      ">epoch=58, MSE=31.979, abs fraction of change=0.000249\n",
      ">epoch=59, MSE=31.987, abs fraction of change=0.000246\n",
      ">epoch=60, MSE=31.995, abs fraction of change=0.000244\n",
      ">epoch=61, MSE=32.002, abs fraction of change=0.000241\n",
      ">epoch=62, MSE=32.010, abs fraction of change=0.000238\n",
      ">epoch=63, MSE=32.017, abs fraction of change=0.000236\n",
      ">epoch=64, MSE=32.025, abs fraction of change=0.000233\n",
      ">epoch=65, MSE=32.032, abs fraction of change=0.000230\n",
      ">epoch=66, MSE=32.040, abs fraction of change=0.000228\n",
      ">epoch=67, MSE=32.047, abs fraction of change=0.000225\n",
      ">epoch=68, MSE=32.054, abs fraction of change=0.000223\n",
      ">epoch=69, MSE=32.061, abs fraction of change=0.000220\n",
      ">epoch=70, MSE=32.068, abs fraction of change=0.000218\n",
      ">epoch=71, MSE=32.075, abs fraction of change=0.000215\n",
      ">epoch=72, MSE=32.082, abs fraction of change=0.000213\n",
      ">epoch=73, MSE=32.088, abs fraction of change=0.000211\n",
      ">epoch=74, MSE=32.095, abs fraction of change=0.000208\n",
      ">epoch=75, MSE=32.102, abs fraction of change=0.000206\n",
      ">epoch=76, MSE=32.108, abs fraction of change=0.000204\n",
      ">epoch=77, MSE=32.115, abs fraction of change=0.000201\n",
      ">epoch=78, MSE=32.121, abs fraction of change=0.000199\n",
      ">epoch=79, MSE=32.127, abs fraction of change=0.000197\n",
      ">epoch=80, MSE=32.134, abs fraction of change=0.000195\n",
      ">epoch=81, MSE=32.140, abs fraction of change=0.000193\n",
      ">epoch=82, MSE=32.146, abs fraction of change=0.000191\n",
      ">epoch=83, MSE=32.152, abs fraction of change=0.000188\n",
      ">epoch=84, MSE=32.158, abs fraction of change=0.000186\n",
      ">epoch=85, MSE=32.164, abs fraction of change=0.000184\n",
      ">epoch=86, MSE=32.170, abs fraction of change=0.000182\n",
      ">epoch=87, MSE=32.176, abs fraction of change=0.000180\n",
      ">epoch=88, MSE=32.181, abs fraction of change=0.000178\n",
      ">epoch=89, MSE=32.187, abs fraction of change=0.000176\n",
      ">epoch=90, MSE=32.193, abs fraction of change=0.000174\n",
      ">epoch=91, MSE=32.198, abs fraction of change=0.000172\n",
      ">epoch=92, MSE=32.204, abs fraction of change=0.000170\n",
      ">epoch=93, MSE=32.209, abs fraction of change=0.000169\n",
      ">epoch=94, MSE=32.215, abs fraction of change=0.000167\n",
      ">epoch=95, MSE=32.220, abs fraction of change=0.000165\n",
      ">epoch=96, MSE=32.225, abs fraction of change=0.000163\n",
      ">epoch=97, MSE=32.230, abs fraction of change=0.000161\n",
      ">epoch=98, MSE=32.235, abs fraction of change=0.000160\n",
      ">epoch=99, MSE=32.241, abs fraction of change=0.000158\n",
      ">epoch=100, MSE=32.246, abs fraction of change=0.000156\n",
      ">epoch=101, MSE=32.251, abs fraction of change=0.000154\n",
      ">epoch=102, MSE=32.255, abs fraction of change=0.000153\n",
      ">epoch=103, MSE=32.260, abs fraction of change=0.000151\n",
      ">epoch=104, MSE=32.265, abs fraction of change=0.000149\n",
      ">epoch=105, MSE=32.270, abs fraction of change=0.000148\n",
      ">epoch=106, MSE=32.275, abs fraction of change=0.000146\n",
      ">epoch=107, MSE=32.279, abs fraction of change=0.000145\n",
      ">epoch=108, MSE=32.284, abs fraction of change=0.000143\n",
      ">epoch=109, MSE=32.289, abs fraction of change=0.000141\n",
      ">epoch=110, MSE=32.293, abs fraction of change=0.000140\n",
      ">epoch=111, MSE=32.298, abs fraction of change=0.000138\n",
      ">epoch=112, MSE=32.302, abs fraction of change=0.000137\n",
      ">epoch=113, MSE=32.306, abs fraction of change=0.000135\n",
      ">epoch=114, MSE=32.311, abs fraction of change=0.000134\n",
      ">epoch=115, MSE=32.315, abs fraction of change=0.000132\n",
      ">epoch=116, MSE=32.319, abs fraction of change=0.000131\n",
      ">epoch=117, MSE=32.323, abs fraction of change=0.000130\n",
      ">epoch=118, MSE=32.327, abs fraction of change=0.000128\n",
      ">epoch=119, MSE=32.332, abs fraction of change=0.000127\n",
      ">epoch=120, MSE=32.336, abs fraction of change=0.000125\n",
      ">epoch=121, MSE=32.340, abs fraction of change=0.000124\n",
      ">epoch=122, MSE=32.344, abs fraction of change=0.000123\n",
      ">epoch=123, MSE=32.347, abs fraction of change=0.000121\n",
      ">epoch=124, MSE=32.351, abs fraction of change=0.000120\n",
      ">epoch=125, MSE=32.355, abs fraction of change=0.000119\n",
      ">epoch=126, MSE=32.359, abs fraction of change=0.000117\n",
      ">epoch=127, MSE=32.363, abs fraction of change=0.000116\n",
      ">epoch=128, MSE=32.366, abs fraction of change=0.000115\n",
      ">epoch=129, MSE=32.370, abs fraction of change=0.000113\n",
      ">epoch=130, MSE=32.374, abs fraction of change=0.000112\n",
      ">epoch=131, MSE=32.377, abs fraction of change=0.000111\n",
      ">epoch=132, MSE=32.381, abs fraction of change=0.000110\n",
      ">epoch=133, MSE=32.384, abs fraction of change=0.000108\n",
      ">epoch=134, MSE=32.388, abs fraction of change=0.000107\n",
      ">epoch=135, MSE=32.391, abs fraction of change=0.000106\n",
      ">epoch=136, MSE=32.395, abs fraction of change=0.000105\n",
      ">epoch=137, MSE=32.398, abs fraction of change=0.000104\n",
      ">epoch=138, MSE=32.401, abs fraction of change=0.000103\n",
      ">epoch=139, MSE=32.405, abs fraction of change=0.000101\n",
      ">epoch=140, MSE=32.408, abs fraction of change=0.000100\n",
      "Epoch need:142\n"
     ]
    }
   ],
   "source": [
    "# normalize inputs\n",
    "\n",
    "minmax = dataset_minmax(trainingSet)\n",
    "normalize_data(trainingSet, minmax)\n",
    "\n",
    "learning_rate = 0.1\n",
    "n_epoch = 300\n",
    "n_hidden = 4\n",
    "\n",
    "epoch = back_propagate(trainingSet, learning_rate, n_epoch, n_hidden)\n",
    "results.append(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- lrate=0.200 -----------------\n",
      ">epoch=0, MSE=164.342, abs fraction of change=0.000000\n",
      ">epoch=1, MSE=171.805, abs fraction of change=0.045414\n",
      ">epoch=2, MSE=174.669, abs fraction of change=0.016668\n",
      ">epoch=3, MSE=177.168, abs fraction of change=0.014310\n",
      ">epoch=4, MSE=179.254, abs fraction of change=0.011770\n",
      ">epoch=5, MSE=180.957, abs fraction of change=0.009500\n",
      ">epoch=6, MSE=182.341, abs fraction of change=0.007651\n",
      ">epoch=7, MSE=183.471, abs fraction of change=0.006196\n",
      ">epoch=8, MSE=184.398, abs fraction of change=0.005053\n",
      ">epoch=9, MSE=185.163, abs fraction of change=0.004150\n",
      ">epoch=10, MSE=185.800, abs fraction of change=0.003440\n",
      ">epoch=11, MSE=186.335, abs fraction of change=0.002881\n",
      ">epoch=12, MSE=186.789, abs fraction of change=0.002432\n",
      ">epoch=13, MSE=187.175, abs fraction of change=0.002066\n",
      ">epoch=14, MSE=187.505, abs fraction of change=0.001767\n",
      ">epoch=15, MSE=187.791, abs fraction of change=0.001522\n",
      ">epoch=16, MSE=188.039, abs fraction of change=0.001321\n",
      ">epoch=17, MSE=188.256, abs fraction of change=0.001155\n",
      ">epoch=18, MSE=188.447, abs fraction of change=0.001016\n",
      ">epoch=19, MSE=188.617, abs fraction of change=0.000899\n",
      ">epoch=20, MSE=188.768, abs fraction of change=0.000799\n",
      ">epoch=21, MSE=188.902, abs fraction of change=0.000714\n",
      ">epoch=22, MSE=189.023, abs fraction of change=0.000641\n",
      ">epoch=23, MSE=189.133, abs fraction of change=0.000578\n",
      ">epoch=24, MSE=189.232, abs fraction of change=0.000524\n",
      ">epoch=25, MSE=189.322, abs fraction of change=0.000476\n",
      ">epoch=26, MSE=189.404, abs fraction of change=0.000434\n",
      ">epoch=27, MSE=189.479, abs fraction of change=0.000397\n",
      ">epoch=28, MSE=189.548, abs fraction of change=0.000363\n",
      ">epoch=29, MSE=189.611, abs fraction of change=0.000334\n",
      ">epoch=30, MSE=189.669, abs fraction of change=0.000308\n",
      ">epoch=31, MSE=189.723, abs fraction of change=0.000284\n",
      ">epoch=32, MSE=189.773, abs fraction of change=0.000263\n",
      ">epoch=33, MSE=189.820, abs fraction of change=0.000244\n",
      ">epoch=34, MSE=189.863, abs fraction of change=0.000227\n",
      ">epoch=35, MSE=189.903, abs fraction of change=0.000212\n",
      ">epoch=36, MSE=189.940, abs fraction of change=0.000198\n",
      ">epoch=37, MSE=189.976, abs fraction of change=0.000185\n",
      ">epoch=38, MSE=190.008, abs fraction of change=0.000174\n",
      ">epoch=39, MSE=190.039, abs fraction of change=0.000163\n",
      ">epoch=40, MSE=190.069, abs fraction of change=0.000153\n",
      ">epoch=41, MSE=190.096, abs fraction of change=0.000145\n",
      ">epoch=42, MSE=190.122, abs fraction of change=0.000137\n",
      ">epoch=43, MSE=190.147, abs fraction of change=0.000129\n",
      ">epoch=44, MSE=190.170, abs fraction of change=0.000122\n",
      ">epoch=45, MSE=190.192, abs fraction of change=0.000116\n",
      ">epoch=46, MSE=190.213, abs fraction of change=0.000110\n",
      ">epoch=47, MSE=190.233, abs fraction of change=0.000105\n",
      "Epoch need:49\n"
     ]
    }
   ],
   "source": [
    "# normalize inputs\n",
    "dataset = list(lines)\n",
    "trainingSet = loadDataset(dataset) #reload data\n",
    "minmax = dataset_minmax(trainingSet)\n",
    "normalize_data(trainingSet, minmax)\n",
    "\n",
    "learning_rate = 0.2\n",
    "n_epoch = 300\n",
    "n_hidden = 4\n",
    "\n",
    "epoch = back_propagate(trainingSet, learning_rate, n_epoch, n_hidden)\n",
    "results.append(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- lrate=0.300 -----------------\n",
      ">epoch=0, MSE=71.576, abs fraction of change=0.000000\n",
      ">epoch=1, MSE=77.889, abs fraction of change=0.088201\n",
      ">epoch=2, MSE=79.594, abs fraction of change=0.021902\n",
      ">epoch=3, MSE=81.188, abs fraction of change=0.020020\n",
      ">epoch=4, MSE=82.593, abs fraction of change=0.017311\n",
      ">epoch=5, MSE=83.792, abs fraction of change=0.014517\n",
      ">epoch=6, MSE=84.799, abs fraction of change=0.012018\n",
      ">epoch=7, MSE=85.641, abs fraction of change=0.009930\n",
      ">epoch=8, MSE=86.347, abs fraction of change=0.008235\n",
      ">epoch=9, MSE=86.938, abs fraction of change=0.006847\n",
      ">epoch=10, MSE=87.434, abs fraction of change=0.005700\n",
      ">epoch=11, MSE=87.850, abs fraction of change=0.004765\n",
      ">epoch=12, MSE=88.203, abs fraction of change=0.004018\n",
      ">epoch=13, MSE=88.505, abs fraction of change=0.003425\n",
      ">epoch=14, MSE=88.766, abs fraction of change=0.002950\n",
      ">epoch=15, MSE=88.994, abs fraction of change=0.002564\n",
      ">epoch=16, MSE=89.194, abs fraction of change=0.002248\n",
      ">epoch=17, MSE=89.371, abs fraction of change=0.001985\n",
      ">epoch=18, MSE=89.528, abs fraction of change=0.001761\n",
      ">epoch=19, MSE=89.669, abs fraction of change=0.001565\n",
      ">epoch=20, MSE=89.793, abs fraction of change=0.001391\n",
      ">epoch=21, MSE=89.904, abs fraction of change=0.001234\n",
      ">epoch=22, MSE=90.003, abs fraction of change=0.001096\n",
      ">epoch=23, MSE=90.091, abs fraction of change=0.000976\n",
      ">epoch=24, MSE=90.169, abs fraction of change=0.000873\n",
      ">epoch=25, MSE=90.240, abs fraction of change=0.000785\n",
      ">epoch=26, MSE=90.304, abs fraction of change=0.000709\n",
      ">epoch=27, MSE=90.362, abs fraction of change=0.000645\n",
      ">epoch=28, MSE=90.416, abs fraction of change=0.000589\n",
      ">epoch=29, MSE=90.465, abs fraction of change=0.000541\n",
      ">epoch=30, MSE=90.510, abs fraction of change=0.000500\n",
      ">epoch=31, MSE=90.552, abs fraction of change=0.000464\n",
      ">epoch=32, MSE=90.591, abs fraction of change=0.000432\n",
      ">epoch=33, MSE=90.628, abs fraction of change=0.000405\n",
      ">epoch=34, MSE=90.662, abs fraction of change=0.000380\n",
      ">epoch=35, MSE=90.694, abs fraction of change=0.000357\n",
      ">epoch=36, MSE=90.725, abs fraction of change=0.000337\n",
      ">epoch=37, MSE=90.754, abs fraction of change=0.000318\n",
      ">epoch=38, MSE=90.781, abs fraction of change=0.000300\n",
      ">epoch=39, MSE=90.807, abs fraction of change=0.000284\n",
      ">epoch=40, MSE=90.831, abs fraction of change=0.000268\n",
      ">epoch=41, MSE=90.854, abs fraction of change=0.000253\n",
      ">epoch=42, MSE=90.876, abs fraction of change=0.000239\n",
      ">epoch=43, MSE=90.896, abs fraction of change=0.000226\n",
      ">epoch=44, MSE=90.916, abs fraction of change=0.000213\n",
      ">epoch=45, MSE=90.934, abs fraction of change=0.000201\n",
      ">epoch=46, MSE=90.951, abs fraction of change=0.000190\n",
      ">epoch=47, MSE=90.968, abs fraction of change=0.000179\n",
      ">epoch=48, MSE=90.983, abs fraction of change=0.000169\n",
      ">epoch=49, MSE=90.997, abs fraction of change=0.000160\n",
      ">epoch=50, MSE=91.011, abs fraction of change=0.000151\n",
      ">epoch=51, MSE=91.024, abs fraction of change=0.000143\n",
      ">epoch=52, MSE=91.036, abs fraction of change=0.000135\n",
      ">epoch=53, MSE=91.048, abs fraction of change=0.000128\n",
      ">epoch=54, MSE=91.059, abs fraction of change=0.000122\n",
      ">epoch=55, MSE=91.070, abs fraction of change=0.000115\n",
      ">epoch=56, MSE=91.080, abs fraction of change=0.000110\n",
      ">epoch=57, MSE=91.089, abs fraction of change=0.000105\n",
      "Epoch need:59\n"
     ]
    }
   ],
   "source": [
    "# normalize inputs\n",
    "trainingSet = loadDataset(dataset) #reload data\n",
    "minmax = dataset_minmax(trainingSet)\n",
    "normalize_data(trainingSet, minmax)\n",
    "\n",
    "learning_rate = 0.3\n",
    "n_epoch = 300\n",
    "n_hidden = 4\n",
    "\n",
    "epoch = back_propagate(trainingSet, learning_rate, n_epoch, n_hidden)\n",
    "results.append(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- lrate=0.400 -----------------\n",
      ">epoch=0, MSE=87.168, abs fraction of change=0.000000\n",
      ">epoch=1, MSE=96.451, abs fraction of change=0.106491\n",
      ">epoch=2, MSE=100.811, abs fraction of change=0.045208\n",
      ">epoch=3, MSE=104.355, abs fraction of change=0.035151\n",
      ">epoch=4, MSE=106.995, abs fraction of change=0.025297\n",
      ">epoch=5, MSE=108.934, abs fraction of change=0.018122\n",
      ">epoch=6, MSE=110.362, abs fraction of change=0.013116\n",
      ">epoch=7, MSE=111.415, abs fraction of change=0.009537\n",
      ">epoch=8, MSE=112.202, abs fraction of change=0.007066\n",
      ">epoch=9, MSE=112.806, abs fraction of change=0.005381\n",
      ">epoch=10, MSE=113.280, abs fraction of change=0.004201\n",
      ">epoch=11, MSE=113.661, abs fraction of change=0.003367\n",
      ">epoch=12, MSE=113.975, abs fraction of change=0.002760\n",
      ">epoch=13, MSE=114.236, abs fraction of change=0.002286\n",
      ">epoch=14, MSE=114.453, abs fraction of change=0.001901\n",
      ">epoch=15, MSE=114.634, abs fraction of change=0.001587\n",
      ">epoch=16, MSE=114.788, abs fraction of change=0.001337\n",
      ">epoch=17, MSE=114.918, abs fraction of change=0.001138\n",
      ">epoch=18, MSE=115.031, abs fraction of change=0.000979\n",
      ">epoch=19, MSE=115.129, abs fraction of change=0.000851\n",
      ">epoch=20, MSE=115.215, abs fraction of change=0.000748\n",
      ">epoch=21, MSE=115.291, abs fraction of change=0.000663\n",
      ">epoch=22, MSE=115.360, abs fraction of change=0.000594\n",
      ">epoch=23, MSE=115.421, abs fraction of change=0.000536\n",
      ">epoch=24, MSE=115.478, abs fraction of change=0.000486\n",
      ">epoch=25, MSE=115.529, abs fraction of change=0.000444\n",
      ">epoch=26, MSE=115.576, abs fraction of change=0.000406\n",
      ">epoch=27, MSE=115.619, abs fraction of change=0.000372\n",
      ">epoch=28, MSE=115.658, abs fraction of change=0.000342\n",
      ">epoch=29, MSE=115.694, abs fraction of change=0.000314\n",
      ">epoch=30, MSE=115.728, abs fraction of change=0.000289\n",
      ">epoch=31, MSE=115.759, abs fraction of change=0.000266\n",
      ">epoch=32, MSE=115.787, abs fraction of change=0.000245\n",
      ">epoch=33, MSE=115.813, abs fraction of change=0.000226\n",
      ">epoch=34, MSE=115.837, abs fraction of change=0.000209\n",
      ">epoch=35, MSE=115.860, abs fraction of change=0.000194\n",
      ">epoch=36, MSE=115.881, abs fraction of change=0.000180\n",
      ">epoch=37, MSE=115.900, abs fraction of change=0.000167\n",
      ">epoch=38, MSE=115.918, abs fraction of change=0.000156\n",
      ">epoch=39, MSE=115.935, abs fraction of change=0.000146\n",
      ">epoch=40, MSE=115.951, abs fraction of change=0.000136\n",
      ">epoch=41, MSE=115.966, abs fraction of change=0.000128\n",
      ">epoch=42, MSE=115.980, abs fraction of change=0.000120\n",
      ">epoch=43, MSE=115.993, abs fraction of change=0.000113\n",
      ">epoch=44, MSE=116.005, abs fraction of change=0.000107\n",
      ">epoch=45, MSE=116.017, abs fraction of change=0.000102\n",
      "Epoch need:47\n"
     ]
    }
   ],
   "source": [
    "# normalize inputs\n",
    "trainingSet = loadDataset(dataset) #reload data\n",
    "minmax = dataset_minmax(trainingSet)\n",
    "normalize_data(trainingSet, minmax)\n",
    "\n",
    "learning_rate = 0.4\n",
    "n_epoch = 300\n",
    "n_hidden = 4\n",
    "\n",
    "epoch = back_propagate(trainingSet, learning_rate, n_epoch, n_hidden)\n",
    "results.append(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- lrate=0.500 -----------------\n",
      ">epoch=0, MSE=102.874, abs fraction of change=0.000000\n",
      ">epoch=1, MSE=116.641, abs fraction of change=0.133823\n",
      ">epoch=2, MSE=123.851, abs fraction of change=0.061810\n",
      ">epoch=3, MSE=128.472, abs fraction of change=0.037308\n",
      ">epoch=4, MSE=131.345, abs fraction of change=0.022369\n",
      ">epoch=5, MSE=133.172, abs fraction of change=0.013904\n",
      ">epoch=6, MSE=134.358, abs fraction of change=0.008909\n",
      ">epoch=7, MSE=135.175, abs fraction of change=0.006084\n",
      ">epoch=8, MSE=135.769, abs fraction of change=0.004389\n",
      ">epoch=9, MSE=136.219, abs fraction of change=0.003318\n",
      ">epoch=10, MSE=136.570, abs fraction of change=0.002573\n",
      ">epoch=11, MSE=136.845, abs fraction of change=0.002013\n",
      ">epoch=12, MSE=137.063, abs fraction of change=0.001595\n",
      ">epoch=13, MSE=137.239, abs fraction of change=0.001286\n",
      ">epoch=14, MSE=137.384, abs fraction of change=0.001058\n",
      ">epoch=15, MSE=137.506, abs fraction of change=0.000887\n",
      ">epoch=16, MSE=137.610, abs fraction of change=0.000757\n",
      ">epoch=17, MSE=137.701, abs fraction of change=0.000655\n",
      ">epoch=18, MSE=137.780, abs fraction of change=0.000575\n",
      ">epoch=19, MSE=137.850, abs fraction of change=0.000509\n",
      ">epoch=20, MSE=137.912, abs fraction of change=0.000453\n",
      ">epoch=21, MSE=137.968, abs fraction of change=0.000405\n",
      ">epoch=22, MSE=138.018, abs fraction of change=0.000363\n",
      ">epoch=23, MSE=138.063, abs fraction of change=0.000326\n",
      ">epoch=24, MSE=138.104, abs fraction of change=0.000293\n",
      ">epoch=25, MSE=138.140, abs fraction of change=0.000264\n",
      ">epoch=26, MSE=138.173, abs fraction of change=0.000239\n",
      ">epoch=27, MSE=138.203, abs fraction of change=0.000217\n",
      ">epoch=28, MSE=138.231, abs fraction of change=0.000197\n",
      ">epoch=29, MSE=138.255, abs fraction of change=0.000179\n",
      ">epoch=30, MSE=138.278, abs fraction of change=0.000164\n",
      ">epoch=31, MSE=138.299, abs fraction of change=0.000151\n",
      ">epoch=32, MSE=138.318, abs fraction of change=0.000139\n",
      ">epoch=33, MSE=138.336, abs fraction of change=0.000129\n",
      ">epoch=34, MSE=138.353, abs fraction of change=0.000120\n",
      ">epoch=35, MSE=138.368, abs fraction of change=0.000112\n",
      ">epoch=36, MSE=138.382, abs fraction of change=0.000104\n",
      "Epoch need:38\n"
     ]
    }
   ],
   "source": [
    "# normalize inputs\n",
    "trainingSet = loadDataset(dataset) #reload data\n",
    "minmax = dataset_minmax(trainingSet)\n",
    "normalize_data(trainingSet, minmax)\n",
    "\n",
    "learning_rate = 0.5\n",
    "n_epoch = 300\n",
    "n_hidden = 4\n",
    "\n",
    "epoch = back_propagate(trainingSet, learning_rate, n_epoch, n_hidden)\n",
    "results.append(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([0.1, 0.2, 0.3, 0.4, 0.5], results, 'r')\n",
    "plt.xlabel(\"Learning rate\")\n",
    "plt.ylabel(\"Number of epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
